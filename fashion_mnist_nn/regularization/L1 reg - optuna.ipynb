{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edf2af4-8c03-4caf-a111-91044f6c0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import optuna\n",
    "import optuna.visualization as ov\n",
    "import pickle\n",
    "\n",
    "from sgd_L1 import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0c8143-3f11-4913-bc48-b509c3735a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train_data.pkl\", \"rb\") as train_file:\n",
    "    train_data = pickle.load(train_file)\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "rng.shuffle(train_data)\n",
    "validation_data = train_data[:5000]\n",
    "train_data = train_data[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f90b6c-37e6-4c78-bf1d-ad24a9c091a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float(\"learning rate\", 1e-5, 1e-3, log=True)\n",
    "    L1_lambda = trial.suggest_float(\"L1 lambda\", 1e-2, 10, log=True)\n",
    "    nn = NeuralNetwork(\n",
    "        [28*28, 1024, 512, 128, 10], # layers size\n",
    "        learning_rate,               # learning rate\n",
    "        L1_lambda,                   # L1 lambda\n",
    "        64,                          # mini batch size\n",
    "        5                            # training epochs\n",
    "    )\n",
    "    accuracy, _ = nn.train(train_data, validation_data)\n",
    "    return accuracy[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a97878-a4be-4361-b1c3-0ffdb047618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-24 18:42:14,007] A new study created in memory with name: no-name-c84d6ffe-ff8f-47f0-847b-d6b070263e0d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-train stats\n",
      "==> Accuracy: 11.0%, Avg loss: 7.717746\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 8.018305 [mini-batch 0 / 859]\n",
      "loss: 1.703927 [mini-batch 100 / 859]\n",
      "loss: 1.583194 [mini-batch 200 / 859]\n",
      "loss: 1.212510 [mini-batch 300 / 859]\n",
      "loss: 0.963275 [mini-batch 400 / 859]\n",
      "loss: 1.018145 [mini-batch 500 / 859]\n",
      "loss: 1.222212 [mini-batch 600 / 859]\n",
      "loss: 0.859638 [mini-batch 700 / 859]\n",
      "loss: 1.161640 [mini-batch 800 / 859]\n",
      "==> Accuracy: 69.3%, Avg loss: 0.864247\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.811941 [mini-batch 0 / 859]\n",
      "loss: 0.985837 [mini-batch 100 / 859]\n",
      "loss: 0.732697 [mini-batch 200 / 859]\n",
      "loss: 0.897589 [mini-batch 300 / 859]\n",
      "loss: 0.718318 [mini-batch 400 / 859]\n",
      "loss: 0.689201 [mini-batch 500 / 859]\n",
      "loss: 0.584526 [mini-batch 600 / 859]\n",
      "loss: 0.642675 [mini-batch 700 / 859]\n",
      "loss: 0.763323 [mini-batch 800 / 859]\n",
      "==> Accuracy: 74.6%, Avg loss: 0.722654\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.599678 [mini-batch 0 / 859]\n",
      "loss: 0.918653 [mini-batch 100 / 859]\n",
      "loss: 0.647312 [mini-batch 200 / 859]\n",
      "loss: 0.558162 [mini-batch 300 / 859]\n",
      "loss: 0.734981 [mini-batch 400 / 859]\n",
      "loss: 0.660283 [mini-batch 500 / 859]\n",
      "loss: 0.699169 [mini-batch 600 / 859]\n",
      "loss: 0.645159 [mini-batch 700 / 859]\n",
      "loss: 0.722202 [mini-batch 800 / 859]\n",
      "==> Accuracy: 77.0%, Avg loss: 0.654063\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.557820 [mini-batch 0 / 859]\n",
      "loss: 0.543320 [mini-batch 100 / 859]\n",
      "loss: 0.565193 [mini-batch 200 / 859]\n",
      "loss: 0.660977 [mini-batch 300 / 859]\n",
      "loss: 0.605471 [mini-batch 400 / 859]\n",
      "loss: 0.678607 [mini-batch 500 / 859]\n",
      "loss: 0.484753 [mini-batch 600 / 859]\n",
      "loss: 0.747024 [mini-batch 700 / 859]\n",
      "loss: 0.656348 [mini-batch 800 / 859]\n",
      "==> Accuracy: 78.7%, Avg loss: 0.616758\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.773885 [mini-batch 0 / 859]\n",
      "loss: 0.474900 [mini-batch 100 / 859]\n",
      "loss: 0.747016 [mini-batch 200 / 859]\n",
      "loss: 0.758810 [mini-batch 300 / 859]\n",
      "loss: 0.909504 [mini-batch 400 / 859]\n",
      "loss: 0.475812 [mini-batch 500 / 859]\n",
      "loss: 0.563092 [mini-batch 600 / 859]\n",
      "loss: 0.835685 [mini-batch 700 / 859]\n",
      "loss: 0.472333 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-24 19:21:52,649] Trial 0 finished with value: 0.7972 and parameters: {'learning rate': 2.169936253375492e-05, 'L1 lambda': 0.8323553239145367}. Best is trial 0 with value: 0.7972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 79.7%, Avg loss: 0.587074\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 3.4%, Avg loss: 6.011395\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 5.944395 [mini-batch 0 / 859]\n",
      "loss: 1.444607 [mini-batch 100 / 859]\n",
      "loss: 1.144224 [mini-batch 200 / 859]\n",
      "loss: 0.972792 [mini-batch 300 / 859]\n",
      "loss: 1.035123 [mini-batch 400 / 859]\n",
      "loss: 0.798382 [mini-batch 500 / 859]\n",
      "loss: 0.633287 [mini-batch 600 / 859]\n",
      "loss: 0.621093 [mini-batch 700 / 859]\n",
      "loss: 0.672375 [mini-batch 800 / 859]\n",
      "==> Accuracy: 74.7%, Avg loss: 0.731129\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.793525 [mini-batch 0 / 859]\n",
      "loss: 0.730231 [mini-batch 100 / 859]\n",
      "loss: 0.702761 [mini-batch 200 / 859]\n",
      "loss: 0.598608 [mini-batch 300 / 859]\n",
      "loss: 0.964593 [mini-batch 400 / 859]\n",
      "loss: 0.618002 [mini-batch 500 / 859]\n",
      "loss: 0.743557 [mini-batch 600 / 859]\n",
      "loss: 0.394572 [mini-batch 700 / 859]\n",
      "loss: 0.714718 [mini-batch 800 / 859]\n",
      "==> Accuracy: 78.5%, Avg loss: 0.619709\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.727972 [mini-batch 0 / 859]\n",
      "loss: 0.805240 [mini-batch 100 / 859]\n",
      "loss: 0.650101 [mini-batch 200 / 859]\n",
      "loss: 0.518255 [mini-batch 300 / 859]\n",
      "loss: 0.596134 [mini-batch 400 / 859]\n",
      "loss: 0.496297 [mini-batch 500 / 859]\n",
      "loss: 0.431782 [mini-batch 600 / 859]\n",
      "loss: 0.614082 [mini-batch 700 / 859]\n",
      "loss: 0.861651 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.0%, Avg loss: 0.590198\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.550876 [mini-batch 0 / 859]\n",
      "loss: 0.529764 [mini-batch 100 / 859]\n",
      "loss: 0.564294 [mini-batch 200 / 859]\n",
      "loss: 0.484532 [mini-batch 300 / 859]\n",
      "loss: 0.801605 [mini-batch 400 / 859]\n",
      "loss: 0.652916 [mini-batch 500 / 859]\n",
      "loss: 0.578754 [mini-batch 600 / 859]\n",
      "loss: 0.743295 [mini-batch 700 / 859]\n",
      "loss: 0.550657 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.7%, Avg loss: 0.539151\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.713007 [mini-batch 0 / 859]\n",
      "loss: 0.494446 [mini-batch 100 / 859]\n",
      "loss: 0.761590 [mini-batch 200 / 859]\n",
      "loss: 0.512164 [mini-batch 300 / 859]\n",
      "loss: 0.520261 [mini-batch 400 / 859]\n",
      "loss: 0.648729 [mini-batch 500 / 859]\n",
      "loss: 0.604742 [mini-batch 600 / 859]\n",
      "loss: 0.628581 [mini-batch 700 / 859]\n",
      "loss: 0.610491 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-24 20:03:38,839] Trial 1 finished with value: 0.8228 and parameters: {'learning rate': 4.398328301496164e-05, 'L1 lambda': 0.028870474974720013}. Best is trial 1 with value: 0.8228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 82.3%, Avg loss: 0.522688\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 14.6%, Avg loss: 7.501366\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.870569 [mini-batch 0 / 859]\n",
      "loss: 1.043361 [mini-batch 100 / 859]\n",
      "loss: 0.839007 [mini-batch 200 / 859]\n",
      "loss: 0.807767 [mini-batch 300 / 859]\n",
      "loss: 0.623967 [mini-batch 400 / 859]\n",
      "loss: 0.860438 [mini-batch 500 / 859]\n",
      "loss: 0.850830 [mini-batch 600 / 859]\n",
      "loss: 0.644695 [mini-batch 700 / 859]\n",
      "loss: 0.786097 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.9%, Avg loss: 0.519546\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.536973 [mini-batch 0 / 859]\n",
      "loss: 0.501551 [mini-batch 100 / 859]\n",
      "loss: 0.497461 [mini-batch 200 / 859]\n",
      "loss: 0.673879 [mini-batch 300 / 859]\n",
      "loss: 0.517692 [mini-batch 400 / 859]\n",
      "loss: 0.480821 [mini-batch 500 / 859]\n",
      "loss: 0.589503 [mini-batch 600 / 859]\n",
      "loss: 0.497396 [mini-batch 700 / 859]\n",
      "loss: 0.688643 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.7%, Avg loss: 0.499637\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.585830 [mini-batch 0 / 859]\n",
      "loss: 0.820406 [mini-batch 100 / 859]\n",
      "loss: 0.387424 [mini-batch 200 / 859]\n",
      "loss: 0.493179 [mini-batch 300 / 859]\n",
      "loss: 0.483881 [mini-batch 400 / 859]\n",
      "loss: 0.369578 [mini-batch 500 / 859]\n",
      "loss: 0.435798 [mini-batch 600 / 859]\n",
      "loss: 0.594731 [mini-batch 700 / 859]\n",
      "loss: 0.547697 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.8%, Avg loss: 0.501191\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.639589 [mini-batch 0 / 859]\n",
      "loss: 0.387614 [mini-batch 100 / 859]\n",
      "loss: 0.419791 [mini-batch 200 / 859]\n",
      "loss: 0.465327 [mini-batch 300 / 859]\n",
      "loss: 0.503109 [mini-batch 400 / 859]\n",
      "loss: 0.665287 [mini-batch 500 / 859]\n",
      "loss: 0.437431 [mini-batch 600 / 859]\n",
      "loss: 0.465758 [mini-batch 700 / 859]\n",
      "loss: 0.692141 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.7%, Avg loss: 0.492259\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.485176 [mini-batch 0 / 859]\n",
      "loss: 0.397634 [mini-batch 100 / 859]\n",
      "loss: 0.555336 [mini-batch 200 / 859]\n",
      "loss: 0.558961 [mini-batch 300 / 859]\n",
      "loss: 0.533705 [mini-batch 400 / 859]\n",
      "loss: 0.353691 [mini-batch 500 / 859]\n",
      "loss: 0.396281 [mini-batch 600 / 859]\n",
      "loss: 0.408379 [mini-batch 700 / 859]\n",
      "loss: 0.539510 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-24 20:46:02,712] Trial 2 finished with value: 0.8392 and parameters: {'learning rate': 0.0002472578287788824, 'L1 lambda': 0.6665327794552703}. Best is trial 2 with value: 0.8392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 83.9%, Avg loss: 0.505482\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 12.9%, Avg loss: 8.358166\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 8.655595 [mini-batch 0 / 859]\n",
      "loss: 2.004128 [mini-batch 100 / 859]\n",
      "loss: 1.463768 [mini-batch 200 / 859]\n",
      "loss: 1.348706 [mini-batch 300 / 859]\n",
      "loss: 1.259148 [mini-batch 400 / 859]\n",
      "loss: 1.181559 [mini-batch 500 / 859]\n",
      "loss: 0.945596 [mini-batch 600 / 859]\n",
      "loss: 0.939226 [mini-batch 700 / 859]\n",
      "loss: 0.873238 [mini-batch 800 / 859]\n",
      "==> Accuracy: 67.6%, Avg loss: 0.947034\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 1.099473 [mini-batch 0 / 859]\n",
      "loss: 0.888866 [mini-batch 100 / 859]\n",
      "loss: 0.922066 [mini-batch 200 / 859]\n",
      "loss: 0.968547 [mini-batch 300 / 859]\n",
      "loss: 0.906857 [mini-batch 400 / 859]\n",
      "loss: 0.848454 [mini-batch 500 / 859]\n",
      "loss: 0.783146 [mini-batch 600 / 859]\n",
      "loss: 1.151051 [mini-batch 700 / 859]\n",
      "loss: 0.650549 [mini-batch 800 / 859]\n",
      "==> Accuracy: 73.5%, Avg loss: 0.774678\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.735514 [mini-batch 0 / 859]\n",
      "loss: 1.017541 [mini-batch 100 / 859]\n",
      "loss: 0.624451 [mini-batch 200 / 859]\n",
      "loss: 0.767245 [mini-batch 300 / 859]\n",
      "loss: 0.626968 [mini-batch 400 / 859]\n",
      "loss: 0.635899 [mini-batch 500 / 859]\n",
      "loss: 0.833224 [mini-batch 600 / 859]\n",
      "loss: 0.648866 [mini-batch 700 / 859]\n",
      "loss: 0.829887 [mini-batch 800 / 859]\n",
      "==> Accuracy: 76.2%, Avg loss: 0.702327\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.528063 [mini-batch 0 / 859]\n",
      "loss: 0.827341 [mini-batch 100 / 859]\n",
      "loss: 0.569852 [mini-batch 200 / 859]\n",
      "loss: 0.815205 [mini-batch 300 / 859]\n",
      "loss: 0.734809 [mini-batch 400 / 859]\n",
      "loss: 0.656286 [mini-batch 500 / 859]\n",
      "loss: 0.774831 [mini-batch 600 / 859]\n",
      "loss: 0.627431 [mini-batch 700 / 859]\n",
      "loss: 0.744421 [mini-batch 800 / 859]\n",
      "==> Accuracy: 77.8%, Avg loss: 0.652941\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.587512 [mini-batch 0 / 859]\n",
      "loss: 0.555868 [mini-batch 100 / 859]\n",
      "loss: 0.487436 [mini-batch 200 / 859]\n",
      "loss: 0.801768 [mini-batch 300 / 859]\n",
      "loss: 0.615642 [mini-batch 400 / 859]\n",
      "loss: 0.522562 [mini-batch 500 / 859]\n",
      "loss: 0.801524 [mini-batch 600 / 859]\n",
      "loss: 0.550468 [mini-batch 700 / 859]\n",
      "loss: 1.080112 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-24 21:28:22,339] Trial 3 finished with value: 0.7876 and parameters: {'learning rate': 1.4753369965434447e-05, 'L1 lambda': 0.10303108665538029}. Best is trial 2 with value: 0.8392.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 78.8%, Avg loss: 0.622142\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 13.6%, Avg loss: 4.651895\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 4.349344 [mini-batch 0 / 859]\n",
      "loss: 0.982543 [mini-batch 100 / 859]\n",
      "loss: 0.712921 [mini-batch 200 / 859]\n",
      "loss: 0.650872 [mini-batch 300 / 859]\n",
      "loss: 0.484414 [mini-batch 400 / 859]\n",
      "loss: 0.683044 [mini-batch 500 / 859]\n",
      "loss: 0.636379 [mini-batch 600 / 859]\n",
      "loss: 0.752425 [mini-batch 700 / 859]\n",
      "loss: 0.658382 [mini-batch 800 / 859]\n",
      "==> Accuracy: 79.5%, Avg loss: 0.570887\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.433576 [mini-batch 0 / 859]\n",
      "loss: 0.699359 [mini-batch 100 / 859]\n",
      "loss: 0.737899 [mini-batch 200 / 859]\n",
      "loss: 0.578256 [mini-batch 300 / 859]\n",
      "loss: 0.506058 [mini-batch 400 / 859]\n",
      "loss: 0.532165 [mini-batch 500 / 859]\n",
      "loss: 0.846103 [mini-batch 600 / 859]\n",
      "loss: 0.569907 [mini-batch 700 / 859]\n",
      "loss: 0.501317 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.4%, Avg loss: 0.517622\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.508893 [mini-batch 0 / 859]\n",
      "loss: 0.422552 [mini-batch 100 / 859]\n",
      "loss: 0.559498 [mini-batch 200 / 859]\n",
      "loss: 0.419750 [mini-batch 300 / 859]\n",
      "loss: 0.632096 [mini-batch 400 / 859]\n",
      "loss: 0.485651 [mini-batch 500 / 859]\n",
      "loss: 0.753230 [mini-batch 600 / 859]\n",
      "loss: 0.649346 [mini-batch 700 / 859]\n",
      "loss: 0.544405 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.2%, Avg loss: 0.477463\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.256759 [mini-batch 0 / 859]\n",
      "loss: 0.603712 [mini-batch 100 / 859]\n",
      "loss: 0.646885 [mini-batch 200 / 859]\n",
      "loss: 0.642904 [mini-batch 300 / 859]\n",
      "loss: 0.621123 [mini-batch 400 / 859]\n",
      "loss: 0.447537 [mini-batch 500 / 859]\n",
      "loss: 0.837890 [mini-batch 600 / 859]\n",
      "loss: 0.346806 [mini-batch 700 / 859]\n",
      "loss: 0.483051 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.5%, Avg loss: 0.483000\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.466060 [mini-batch 0 / 859]\n",
      "loss: 0.456769 [mini-batch 100 / 859]\n",
      "loss: 0.553932 [mini-batch 200 / 859]\n",
      "loss: 0.303076 [mini-batch 300 / 859]\n",
      "loss: 0.320545 [mini-batch 400 / 859]\n",
      "loss: 0.487809 [mini-batch 500 / 859]\n",
      "loss: 0.499452 [mini-batch 600 / 859]\n",
      "loss: 0.472428 [mini-batch 700 / 859]\n",
      "loss: 0.516092 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-24 22:10:25,869] Trial 4 finished with value: 0.8426 and parameters: {'learning rate': 0.00013973478878593913, 'L1 lambda': 0.25492135284062234}. Best is trial 4 with value: 0.8426.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 84.3%, Avg loss: 0.449771\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 12.4%, Avg loss: 6.541521\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.423812 [mini-batch 0 / 859]\n",
      "loss: 0.798792 [mini-batch 100 / 859]\n",
      "loss: 0.720886 [mini-batch 200 / 859]\n",
      "loss: 0.724900 [mini-batch 300 / 859]\n",
      "loss: 0.672673 [mini-batch 400 / 859]\n",
      "loss: 0.456234 [mini-batch 500 / 859]\n",
      "loss: 0.721108 [mini-batch 600 / 859]\n",
      "loss: 0.877620 [mini-batch 700 / 859]\n",
      "loss: 0.477498 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.7%, Avg loss: 0.553881\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.589836 [mini-batch 0 / 859]\n",
      "loss: 0.634770 [mini-batch 100 / 859]\n",
      "loss: 0.433098 [mini-batch 200 / 859]\n",
      "loss: 0.407730 [mini-batch 300 / 859]\n",
      "loss: 0.489887 [mini-batch 400 / 859]\n",
      "loss: 0.585025 [mini-batch 500 / 859]\n",
      "loss: 0.506029 [mini-batch 600 / 859]\n",
      "loss: 0.691576 [mini-batch 700 / 859]\n",
      "loss: 0.398282 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.7%, Avg loss: 0.527495\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.534372 [mini-batch 0 / 859]\n",
      "loss: 0.559183 [mini-batch 100 / 859]\n",
      "loss: 0.570752 [mini-batch 200 / 859]\n",
      "loss: 0.542032 [mini-batch 300 / 859]\n",
      "loss: 0.536811 [mini-batch 400 / 859]\n",
      "loss: 0.581314 [mini-batch 500 / 859]\n",
      "loss: 0.638976 [mini-batch 600 / 859]\n",
      "loss: 0.378948 [mini-batch 700 / 859]\n",
      "loss: 0.584374 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.7%, Avg loss: 0.554354\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.388192 [mini-batch 0 / 859]\n",
      "loss: 0.749046 [mini-batch 100 / 859]\n",
      "loss: 0.692490 [mini-batch 200 / 859]\n",
      "loss: 0.511470 [mini-batch 300 / 859]\n",
      "loss: 0.549536 [mini-batch 400 / 859]\n",
      "loss: 0.445453 [mini-batch 500 / 859]\n",
      "loss: 0.538490 [mini-batch 600 / 859]\n",
      "loss: 0.574945 [mini-batch 700 / 859]\n",
      "loss: 0.601268 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.3%, Avg loss: 0.604149\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.737960 [mini-batch 0 / 859]\n",
      "loss: 0.440861 [mini-batch 100 / 859]\n",
      "loss: 0.705900 [mini-batch 200 / 859]\n",
      "loss: 0.571819 [mini-batch 300 / 859]\n",
      "loss: 0.784113 [mini-batch 400 / 859]\n",
      "loss: 0.719814 [mini-batch 500 / 859]\n",
      "loss: 0.690959 [mini-batch 600 / 859]\n",
      "loss: 0.655881 [mini-batch 700 / 859]\n",
      "loss: 0.561891 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-24 22:53:35,395] Trial 5 finished with value: 0.8182 and parameters: {'learning rate': 0.00019915716003017655, 'L1 lambda': 1.2377114322052611}. Best is trial 4 with value: 0.8426.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 81.8%, Avg loss: 0.671031\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 12.1%, Avg loss: 6.448344\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.142630 [mini-batch 0 / 859]\n",
      "loss: 0.778788 [mini-batch 100 / 859]\n",
      "loss: 0.836244 [mini-batch 200 / 859]\n",
      "loss: 0.783984 [mini-batch 300 / 859]\n",
      "loss: 0.711410 [mini-batch 400 / 859]\n",
      "loss: 0.699617 [mini-batch 500 / 859]\n",
      "loss: 0.562819 [mini-batch 600 / 859]\n",
      "loss: 0.480427 [mini-batch 700 / 859]\n",
      "loss: 0.713441 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.1%, Avg loss: 0.583243\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.446075 [mini-batch 0 / 859]\n",
      "loss: 0.513760 [mini-batch 100 / 859]\n",
      "loss: 0.520680 [mini-batch 200 / 859]\n",
      "loss: 0.635940 [mini-batch 300 / 859]\n",
      "loss: 0.634454 [mini-batch 400 / 859]\n",
      "loss: 0.579907 [mini-batch 500 / 859]\n",
      "loss: 0.612484 [mini-batch 600 / 859]\n",
      "loss: 0.690436 [mini-batch 700 / 859]\n",
      "loss: 0.701674 [mini-batch 800 / 859]\n",
      "==> Accuracy: 79.8%, Avg loss: 0.695181\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.566945 [mini-batch 0 / 859]\n",
      "loss: 0.763217 [mini-batch 100 / 859]\n",
      "loss: 0.774370 [mini-batch 200 / 859]\n",
      "loss: 0.874484 [mini-batch 300 / 859]\n",
      "loss: 0.869394 [mini-batch 400 / 859]\n",
      "loss: 0.767544 [mini-batch 500 / 859]\n",
      "loss: 0.931241 [mini-batch 600 / 859]\n",
      "loss: 0.844199 [mini-batch 700 / 859]\n",
      "loss: 0.874252 [mini-batch 800 / 859]\n",
      "==> Accuracy: 74.6%, Avg loss: 0.937753\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.864557 [mini-batch 0 / 859]\n",
      "loss: 0.953922 [mini-batch 100 / 859]\n",
      "loss: 0.814290 [mini-batch 200 / 859]\n",
      "loss: 1.159711 [mini-batch 300 / 859]\n",
      "loss: 1.096036 [mini-batch 400 / 859]\n",
      "loss: 1.140019 [mini-batch 500 / 859]\n",
      "loss: 1.222315 [mini-batch 600 / 859]\n",
      "loss: 1.219529 [mini-batch 700 / 859]\n",
      "loss: 1.179163 [mini-batch 800 / 859]\n",
      "==> Accuracy: 67.4%, Avg loss: 1.183702\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 1.104485 [mini-batch 0 / 859]\n",
      "loss: 1.151021 [mini-batch 100 / 859]\n",
      "loss: 1.219894 [mini-batch 200 / 859]\n",
      "loss: 1.032176 [mini-batch 300 / 859]\n",
      "loss: 1.136673 [mini-batch 400 / 859]\n",
      "loss: 1.108395 [mini-batch 500 / 859]\n",
      "loss: 1.066778 [mini-batch 600 / 859]\n",
      "loss: 1.274987 [mini-batch 700 / 859]\n",
      "loss: 1.077733 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-24 23:36:11,944] Trial 6 finished with value: 0.6088 and parameters: {'learning rate': 0.00037746716853772185, 'L1 lambda': 1.5133102667977998}. Best is trial 4 with value: 0.8426.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 60.9%, Avg loss: 1.102869\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 6.8%, Avg loss: 5.802244\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 5.388658 [mini-batch 0 / 859]\n",
      "loss: 1.876371 [mini-batch 100 / 859]\n",
      "loss: 1.244717 [mini-batch 200 / 859]\n",
      "loss: 1.397596 [mini-batch 300 / 859]\n",
      "loss: 0.906431 [mini-batch 400 / 859]\n",
      "loss: 0.920483 [mini-batch 500 / 859]\n",
      "loss: 1.290118 [mini-batch 600 / 859]\n",
      "loss: 1.053688 [mini-batch 700 / 859]\n",
      "loss: 0.828831 [mini-batch 800 / 859]\n",
      "==> Accuracy: 69.4%, Avg loss: 0.879846\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.846465 [mini-batch 0 / 859]\n",
      "loss: 0.564548 [mini-batch 100 / 859]\n",
      "loss: 0.961762 [mini-batch 200 / 859]\n",
      "loss: 0.696438 [mini-batch 300 / 859]\n",
      "loss: 0.913816 [mini-batch 400 / 859]\n",
      "loss: 0.607060 [mini-batch 500 / 859]\n",
      "loss: 0.864323 [mini-batch 600 / 859]\n",
      "loss: 0.720743 [mini-batch 700 / 859]\n",
      "loss: 0.839491 [mini-batch 800 / 859]\n",
      "==> Accuracy: 74.6%, Avg loss: 0.728954\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 1.039810 [mini-batch 0 / 859]\n",
      "loss: 0.912325 [mini-batch 100 / 859]\n",
      "loss: 0.575415 [mini-batch 200 / 859]\n",
      "loss: 0.630314 [mini-batch 300 / 859]\n",
      "loss: 0.577598 [mini-batch 400 / 859]\n",
      "loss: 0.706460 [mini-batch 500 / 859]\n",
      "loss: 0.592004 [mini-batch 600 / 859]\n",
      "loss: 0.700818 [mini-batch 700 / 859]\n",
      "loss: 0.469167 [mini-batch 800 / 859]\n",
      "==> Accuracy: 76.7%, Avg loss: 0.670619\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.721971 [mini-batch 0 / 859]\n",
      "loss: 0.725002 [mini-batch 100 / 859]\n",
      "loss: 0.547469 [mini-batch 200 / 859]\n",
      "loss: 0.756694 [mini-batch 300 / 859]\n",
      "loss: 0.778094 [mini-batch 400 / 859]\n",
      "loss: 0.533605 [mini-batch 500 / 859]\n",
      "loss: 0.570469 [mini-batch 600 / 859]\n",
      "loss: 0.600552 [mini-batch 700 / 859]\n",
      "loss: 0.765235 [mini-batch 800 / 859]\n",
      "==> Accuracy: 78.2%, Avg loss: 0.625200\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.466596 [mini-batch 0 / 859]\n",
      "loss: 0.643788 [mini-batch 100 / 859]\n",
      "loss: 0.488567 [mini-batch 200 / 859]\n",
      "loss: 0.698778 [mini-batch 300 / 859]\n",
      "loss: 0.832681 [mini-batch 400 / 859]\n",
      "loss: 0.636661 [mini-batch 500 / 859]\n",
      "loss: 0.590168 [mini-batch 600 / 859]\n",
      "loss: 0.534746 [mini-batch 700 / 859]\n",
      "loss: 0.671202 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 00:18:13,359] Trial 7 finished with value: 0.7934 and parameters: {'learning rate': 1.9099947977411154e-05, 'L1 lambda': 0.3812019940386868}. Best is trial 4 with value: 0.8426.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 79.3%, Avg loss: 0.597323\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 9.7%, Avg loss: 5.822123\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 5.606212 [mini-batch 0 / 859]\n",
      "loss: 0.723467 [mini-batch 100 / 859]\n",
      "loss: 0.844879 [mini-batch 200 / 859]\n",
      "loss: 0.954166 [mini-batch 300 / 859]\n",
      "loss: 0.783204 [mini-batch 400 / 859]\n",
      "loss: 0.674075 [mini-batch 500 / 859]\n",
      "loss: 0.963722 [mini-batch 600 / 859]\n",
      "loss: 0.832579 [mini-batch 700 / 859]\n",
      "loss: 0.655845 [mini-batch 800 / 859]\n",
      "==> Accuracy: 78.1%, Avg loss: 0.804867\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.894351 [mini-batch 0 / 859]\n",
      "loss: 0.732812 [mini-batch 100 / 859]\n",
      "loss: 0.912099 [mini-batch 200 / 859]\n",
      "loss: 1.064511 [mini-batch 300 / 859]\n",
      "loss: 1.045432 [mini-batch 400 / 859]\n",
      "loss: 1.066827 [mini-batch 500 / 859]\n",
      "loss: 1.216109 [mini-batch 600 / 859]\n",
      "loss: 1.272562 [mini-batch 700 / 859]\n",
      "loss: 1.416163 [mini-batch 800 / 859]\n",
      "==> Accuracy: 71.5%, Avg loss: 1.434998\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 1.441353 [mini-batch 0 / 859]\n",
      "loss: 1.542424 [mini-batch 100 / 859]\n",
      "loss: 1.666911 [mini-batch 200 / 859]\n",
      "loss: 1.729651 [mini-batch 300 / 859]\n",
      "loss: 1.866919 [mini-batch 400 / 859]\n",
      "loss: 1.929965 [mini-batch 500 / 859]\n",
      "loss: 2.068647 [mini-batch 600 / 859]\n",
      "loss: 2.142595 [mini-batch 700 / 859]\n",
      "loss: 2.205462 [mini-batch 800 / 859]\n",
      "==> Accuracy: 38.0%, Avg loss: 2.229202\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 2.222157 [mini-batch 0 / 859]\n",
      "loss: 2.261297 [mini-batch 100 / 859]\n",
      "loss: 2.287650 [mini-batch 200 / 859]\n",
      "loss: 2.302090 [mini-batch 300 / 859]\n",
      "loss: 2.298625 [mini-batch 400 / 859]\n",
      "loss: 2.295332 [mini-batch 500 / 859]\n",
      "loss: 2.302597 [mini-batch 600 / 859]\n",
      "loss: 2.303844 [mini-batch 700 / 859]\n",
      "loss: 2.296688 [mini-batch 800 / 859]\n",
      "==> Accuracy: 9.8%, Avg loss: 2.303144\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 2.304295 [mini-batch 0 / 859]\n",
      "loss: 2.302992 [mini-batch 100 / 859]\n",
      "loss: 2.305222 [mini-batch 200 / 859]\n",
      "loss: 2.303401 [mini-batch 300 / 859]\n",
      "loss: 2.301706 [mini-batch 400 / 859]\n",
      "loss: 2.304086 [mini-batch 500 / 859]\n",
      "loss: 2.304923 [mini-batch 600 / 859]\n",
      "loss: 2.302825 [mini-batch 700 / 859]\n",
      "loss: 2.299167 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 01:01:09,447] Trial 8 finished with value: 0.0984 and parameters: {'learning rate': 0.00012529007057834556, 'L1 lambda': 5.9260409097524125}. Best is trial 4 with value: 0.8426.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 9.8%, Avg loss: 2.303238\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 12.1%, Avg loss: 7.023937\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.080931 [mini-batch 0 / 859]\n",
      "loss: 0.723481 [mini-batch 100 / 859]\n",
      "loss: 0.597779 [mini-batch 200 / 859]\n",
      "loss: 0.687825 [mini-batch 300 / 859]\n",
      "loss: 0.492005 [mini-batch 400 / 859]\n",
      "loss: 0.556992 [mini-batch 500 / 859]\n",
      "loss: 0.811914 [mini-batch 600 / 859]\n",
      "loss: 0.815937 [mini-batch 700 / 859]\n",
      "loss: 0.969852 [mini-batch 800 / 859]\n",
      "==> Accuracy: 75.9%, Avg loss: 0.964940\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 1.023638 [mini-batch 0 / 859]\n",
      "loss: 1.086373 [mini-batch 100 / 859]\n",
      "loss: 1.261052 [mini-batch 200 / 859]\n",
      "loss: 1.382146 [mini-batch 300 / 859]\n",
      "loss: 1.461103 [mini-batch 400 / 859]\n",
      "loss: 1.439759 [mini-batch 500 / 859]\n",
      "loss: 1.274657 [mini-batch 600 / 859]\n",
      "loss: 1.300609 [mini-batch 700 / 859]\n",
      "loss: 1.266839 [mini-batch 800 / 859]\n",
      "==> Accuracy: 49.9%, Avg loss: 1.283804\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 1.248368 [mini-batch 0 / 859]\n",
      "loss: 1.258861 [mini-batch 100 / 859]\n",
      "loss: 1.149121 [mini-batch 200 / 859]\n",
      "loss: 1.232261 [mini-batch 300 / 859]\n",
      "loss: 1.141415 [mini-batch 400 / 859]\n",
      "loss: 1.140711 [mini-batch 500 / 859]\n",
      "loss: 1.126099 [mini-batch 600 / 859]\n",
      "loss: 1.198857 [mini-batch 700 / 859]\n",
      "loss: 1.179143 [mini-batch 800 / 859]\n",
      "==> Accuracy: 50.2%, Avg loss: 1.148036\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 1.213503 [mini-batch 0 / 859]\n",
      "loss: 1.296275 [mini-batch 100 / 859]\n",
      "loss: 1.229014 [mini-batch 200 / 859]\n",
      "loss: 1.230703 [mini-batch 300 / 859]\n",
      "loss: 0.969070 [mini-batch 400 / 859]\n",
      "loss: 1.092904 [mini-batch 500 / 859]\n",
      "loss: 1.131250 [mini-batch 600 / 859]\n",
      "loss: 1.172360 [mini-batch 700 / 859]\n",
      "loss: 1.135652 [mini-batch 800 / 859]\n",
      "==> Accuracy: 57.1%, Avg loss: 1.080752\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 1.187363 [mini-batch 0 / 859]\n",
      "loss: 1.037394 [mini-batch 100 / 859]\n",
      "loss: 1.043614 [mini-batch 200 / 859]\n",
      "loss: 1.107684 [mini-batch 300 / 859]\n",
      "loss: 1.112566 [mini-batch 400 / 859]\n",
      "loss: 1.082222 [mini-batch 500 / 859]\n",
      "loss: 1.028100 [mini-batch 600 / 859]\n",
      "loss: 1.048346 [mini-batch 700 / 859]\n",
      "loss: 1.034496 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 01:43:21,637] Trial 9 finished with value: 0.5958 and parameters: {'learning rate': 0.0006054129618896587, 'L1 lambda': 2.4017490037780522}. Best is trial 4 with value: 0.8426.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 59.6%, Avg loss: 1.010545\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 7.6%, Avg loss: 6.063529\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.181239 [mini-batch 0 / 859]\n",
      "loss: 1.164417 [mini-batch 100 / 859]\n",
      "loss: 0.977667 [mini-batch 200 / 859]\n",
      "loss: 0.875998 [mini-batch 300 / 859]\n",
      "loss: 0.919110 [mini-batch 400 / 859]\n",
      "loss: 0.960565 [mini-batch 500 / 859]\n",
      "loss: 0.897800 [mini-batch 600 / 859]\n",
      "loss: 0.949067 [mini-batch 700 / 859]\n",
      "loss: 0.362451 [mini-batch 800 / 859]\n",
      "==> Accuracy: 74.7%, Avg loss: 0.717363\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.915156 [mini-batch 0 / 859]\n",
      "loss: 0.890102 [mini-batch 100 / 859]\n",
      "loss: 1.009066 [mini-batch 200 / 859]\n",
      "loss: 0.701255 [mini-batch 300 / 859]\n",
      "loss: 0.647112 [mini-batch 400 / 859]\n",
      "loss: 0.871211 [mini-batch 500 / 859]\n",
      "loss: 0.567237 [mini-batch 600 / 859]\n",
      "loss: 0.552654 [mini-batch 700 / 859]\n",
      "loss: 0.667232 [mini-batch 800 / 859]\n",
      "==> Accuracy: 77.8%, Avg loss: 0.640425\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.483261 [mini-batch 0 / 859]\n",
      "loss: 0.933667 [mini-batch 100 / 859]\n",
      "loss: 0.533368 [mini-batch 200 / 859]\n",
      "loss: 0.726248 [mini-batch 300 / 859]\n",
      "loss: 0.597639 [mini-batch 400 / 859]\n",
      "loss: 0.620755 [mini-batch 500 / 859]\n",
      "loss: 0.547032 [mini-batch 600 / 859]\n",
      "loss: 0.622467 [mini-batch 700 / 859]\n",
      "loss: 0.467659 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.4%, Avg loss: 0.563265\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.595897 [mini-batch 0 / 859]\n",
      "loss: 0.385421 [mini-batch 100 / 859]\n",
      "loss: 0.550531 [mini-batch 200 / 859]\n",
      "loss: 0.541987 [mini-batch 300 / 859]\n",
      "loss: 0.405054 [mini-batch 400 / 859]\n",
      "loss: 0.803545 [mini-batch 500 / 859]\n",
      "loss: 0.552267 [mini-batch 600 / 859]\n",
      "loss: 0.532116 [mini-batch 700 / 859]\n",
      "loss: 0.353815 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.0%, Avg loss: 0.538744\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.422494 [mini-batch 0 / 859]\n",
      "loss: 0.416128 [mini-batch 100 / 859]\n",
      "loss: 0.466836 [mini-batch 200 / 859]\n",
      "loss: 0.615840 [mini-batch 300 / 859]\n",
      "loss: 0.670226 [mini-batch 400 / 859]\n",
      "loss: 0.424027 [mini-batch 500 / 859]\n",
      "loss: 0.440646 [mini-batch 600 / 859]\n",
      "loss: 0.622219 [mini-batch 700 / 859]\n",
      "loss: 0.525089 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 02:24:41,041] Trial 10 finished with value: 0.8194 and parameters: {'learning rate': 6.091255820572607e-05, 'L1 lambda': 0.102729634118518}. Best is trial 4 with value: 0.8426.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 81.9%, Avg loss: 0.516534\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 4.6%, Avg loss: 10.180588\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 9.139818 [mini-batch 0 / 859]\n",
      "loss: 0.654197 [mini-batch 100 / 859]\n",
      "loss: 0.977556 [mini-batch 200 / 859]\n",
      "loss: 0.724801 [mini-batch 300 / 859]\n",
      "loss: 0.582684 [mini-batch 400 / 859]\n",
      "loss: 0.952978 [mini-batch 500 / 859]\n",
      "loss: 0.508315 [mini-batch 600 / 859]\n",
      "loss: 0.854136 [mini-batch 700 / 859]\n",
      "loss: 0.478740 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.9%, Avg loss: 0.516894\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.575393 [mini-batch 0 / 859]\n",
      "loss: 0.531817 [mini-batch 100 / 859]\n",
      "loss: 0.543170 [mini-batch 200 / 859]\n",
      "loss: 0.507036 [mini-batch 300 / 859]\n",
      "loss: 0.625673 [mini-batch 400 / 859]\n",
      "loss: 0.612005 [mini-batch 500 / 859]\n",
      "loss: 0.592355 [mini-batch 600 / 859]\n",
      "loss: 0.501030 [mini-batch 700 / 859]\n",
      "loss: 0.391927 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.6%, Avg loss: 0.478085\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.446279 [mini-batch 0 / 859]\n",
      "loss: 0.635444 [mini-batch 100 / 859]\n",
      "loss: 0.563980 [mini-batch 200 / 859]\n",
      "loss: 0.455893 [mini-batch 300 / 859]\n",
      "loss: 0.352419 [mini-batch 400 / 859]\n",
      "loss: 0.639737 [mini-batch 500 / 859]\n",
      "loss: 0.543842 [mini-batch 600 / 859]\n",
      "loss: 0.296280 [mini-batch 700 / 859]\n",
      "loss: 0.483967 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.1%, Avg loss: 0.453745\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.442151 [mini-batch 0 / 859]\n",
      "loss: 0.311469 [mini-batch 100 / 859]\n",
      "loss: 0.536176 [mini-batch 200 / 859]\n",
      "loss: 0.491628 [mini-batch 300 / 859]\n",
      "loss: 0.390236 [mini-batch 400 / 859]\n",
      "loss: 0.517695 [mini-batch 500 / 859]\n",
      "loss: 0.463011 [mini-batch 600 / 859]\n",
      "loss: 0.474009 [mini-batch 700 / 859]\n",
      "loss: 0.393516 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.8%, Avg loss: 0.435954\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.464528 [mini-batch 0 / 859]\n",
      "loss: 0.305972 [mini-batch 100 / 859]\n",
      "loss: 0.314443 [mini-batch 200 / 859]\n",
      "loss: 0.398626 [mini-batch 300 / 859]\n",
      "loss: 0.367944 [mini-batch 400 / 859]\n",
      "loss: 0.388271 [mini-batch 500 / 859]\n",
      "loss: 0.348379 [mini-batch 600 / 859]\n",
      "loss: 0.292777 [mini-batch 700 / 859]\n",
      "loss: 0.491430 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 03:07:05,332] Trial 11 finished with value: 0.8554 and parameters: {'learning rate': 0.0003215574222167551, 'L1 lambda': 0.18276577643156702}. Best is trial 11 with value: 0.8554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 85.5%, Avg loss: 0.424196\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 13.1%, Avg loss: 5.659675\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 4.909663 [mini-batch 0 / 859]\n",
      "loss: 0.711710 [mini-batch 100 / 859]\n",
      "loss: 0.632482 [mini-batch 200 / 859]\n",
      "loss: 0.584025 [mini-batch 300 / 859]\n",
      "loss: 0.426729 [mini-batch 400 / 859]\n",
      "loss: 0.459653 [mini-batch 500 / 859]\n",
      "loss: 0.484287 [mini-batch 600 / 859]\n",
      "loss: 0.551681 [mini-batch 700 / 859]\n",
      "loss: 0.530193 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.6%, Avg loss: 0.517391\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.427132 [mini-batch 0 / 859]\n",
      "loss: 0.228891 [mini-batch 100 / 859]\n",
      "loss: 0.590509 [mini-batch 200 / 859]\n",
      "loss: 0.389385 [mini-batch 300 / 859]\n",
      "loss: 0.592394 [mini-batch 400 / 859]\n",
      "loss: 0.347245 [mini-batch 500 / 859]\n",
      "loss: 0.666618 [mini-batch 600 / 859]\n",
      "loss: 0.551596 [mini-batch 700 / 859]\n",
      "loss: 0.457193 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.0%, Avg loss: 0.425587\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.586343 [mini-batch 0 / 859]\n",
      "loss: 0.264893 [mini-batch 100 / 859]\n",
      "loss: 0.301138 [mini-batch 200 / 859]\n",
      "loss: 0.387782 [mini-batch 300 / 859]\n",
      "loss: 0.425657 [mini-batch 400 / 859]\n",
      "loss: 0.764198 [mini-batch 500 / 859]\n",
      "loss: 0.516631 [mini-batch 600 / 859]\n",
      "loss: 0.623028 [mini-batch 700 / 859]\n",
      "loss: 0.334559 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.1%, Avg loss: 0.415808\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.508692 [mini-batch 0 / 859]\n",
      "loss: 0.326488 [mini-batch 100 / 859]\n",
      "loss: 0.421080 [mini-batch 200 / 859]\n",
      "loss: 0.483722 [mini-batch 300 / 859]\n",
      "loss: 0.470951 [mini-batch 400 / 859]\n",
      "loss: 0.480519 [mini-batch 500 / 859]\n",
      "loss: 0.517452 [mini-batch 600 / 859]\n",
      "loss: 0.259082 [mini-batch 700 / 859]\n",
      "loss: 0.345460 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.8%, Avg loss: 0.419881\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.358559 [mini-batch 0 / 859]\n",
      "loss: 0.423849 [mini-batch 100 / 859]\n",
      "loss: 0.379310 [mini-batch 200 / 859]\n",
      "loss: 0.339597 [mini-batch 300 / 859]\n",
      "loss: 0.242814 [mini-batch 400 / 859]\n",
      "loss: 0.492316 [mini-batch 500 / 859]\n",
      "loss: 0.357483 [mini-batch 600 / 859]\n",
      "loss: 0.392477 [mini-batch 700 / 859]\n",
      "loss: 0.373843 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 03:49:06,849] Trial 12 finished with value: 0.854 and parameters: {'learning rate': 0.0009864991070211169, 'L1 lambda': 0.106323615247091}. Best is trial 11 with value: 0.8554.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 85.4%, Avg loss: 0.400962\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 10.8%, Avg loss: 5.884810\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 5.561765 [mini-batch 0 / 859]\n",
      "loss: 0.607724 [mini-batch 100 / 859]\n",
      "loss: 0.461415 [mini-batch 200 / 859]\n",
      "loss: 0.794887 [mini-batch 300 / 859]\n",
      "loss: 0.638861 [mini-batch 400 / 859]\n",
      "loss: 0.649578 [mini-batch 500 / 859]\n",
      "loss: 0.571799 [mini-batch 600 / 859]\n",
      "loss: 0.461437 [mini-batch 700 / 859]\n",
      "loss: 0.430848 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.2%, Avg loss: 0.476609\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.566768 [mini-batch 0 / 859]\n",
      "loss: 0.365246 [mini-batch 100 / 859]\n",
      "loss: 0.593184 [mini-batch 200 / 859]\n",
      "loss: 0.347125 [mini-batch 300 / 859]\n",
      "loss: 0.457390 [mini-batch 400 / 859]\n",
      "loss: 0.387866 [mini-batch 500 / 859]\n",
      "loss: 0.227826 [mini-batch 600 / 859]\n",
      "loss: 0.430371 [mini-batch 700 / 859]\n",
      "loss: 0.458141 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.9%, Avg loss: 0.429597\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.422655 [mini-batch 0 / 859]\n",
      "loss: 0.504103 [mini-batch 100 / 859]\n",
      "loss: 0.458968 [mini-batch 200 / 859]\n",
      "loss: 0.581560 [mini-batch 300 / 859]\n",
      "loss: 0.310048 [mini-batch 400 / 859]\n",
      "loss: 0.399067 [mini-batch 500 / 859]\n",
      "loss: 0.302474 [mini-batch 600 / 859]\n",
      "loss: 0.293176 [mini-batch 700 / 859]\n",
      "loss: 0.500432 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.1%, Avg loss: 0.411233\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.277405 [mini-batch 0 / 859]\n",
      "loss: 0.642969 [mini-batch 100 / 859]\n",
      "loss: 0.474466 [mini-batch 200 / 859]\n",
      "loss: 0.422100 [mini-batch 300 / 859]\n",
      "loss: 0.324525 [mini-batch 400 / 859]\n",
      "loss: 0.550772 [mini-batch 500 / 859]\n",
      "loss: 0.333534 [mini-batch 600 / 859]\n",
      "loss: 0.443168 [mini-batch 700 / 859]\n",
      "loss: 0.406966 [mini-batch 800 / 859]\n",
      "==> Accuracy: 86.0%, Avg loss: 0.406708\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.582404 [mini-batch 0 / 859]\n",
      "loss: 0.552260 [mini-batch 100 / 859]\n",
      "loss: 0.603226 [mini-batch 200 / 859]\n",
      "loss: 0.403405 [mini-batch 300 / 859]\n",
      "loss: 0.419633 [mini-batch 400 / 859]\n",
      "loss: 0.614368 [mini-batch 500 / 859]\n",
      "loss: 0.285977 [mini-batch 600 / 859]\n",
      "loss: 0.437863 [mini-batch 700 / 859]\n",
      "loss: 0.526727 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 04:30:58,045] Trial 13 finished with value: 0.8614 and parameters: {'learning rate': 0.0007955636901567097, 'L1 lambda': 0.010021898677856474}. Best is trial 13 with value: 0.8614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 86.1%, Avg loss: 0.396283\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 5.7%, Avg loss: 7.837224\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 9.246407 [mini-batch 0 / 859]\n",
      "loss: 1.031909 [mini-batch 100 / 859]\n",
      "loss: 0.876982 [mini-batch 200 / 859]\n",
      "loss: 0.828088 [mini-batch 300 / 859]\n",
      "loss: 0.596052 [mini-batch 400 / 859]\n",
      "loss: 0.693654 [mini-batch 500 / 859]\n",
      "loss: 0.637185 [mini-batch 600 / 859]\n",
      "loss: 0.451709 [mini-batch 700 / 859]\n",
      "loss: 0.577303 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.5%, Avg loss: 0.480027\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.436736 [mini-batch 0 / 859]\n",
      "loss: 0.549081 [mini-batch 100 / 859]\n",
      "loss: 0.540951 [mini-batch 200 / 859]\n",
      "loss: 0.367983 [mini-batch 300 / 859]\n",
      "loss: 0.485926 [mini-batch 400 / 859]\n",
      "loss: 0.368304 [mini-batch 500 / 859]\n",
      "loss: 0.401474 [mini-batch 600 / 859]\n",
      "loss: 0.436179 [mini-batch 700 / 859]\n",
      "loss: 0.529072 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.8%, Avg loss: 0.436859\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.289070 [mini-batch 0 / 859]\n",
      "loss: 0.488339 [mini-batch 100 / 859]\n",
      "loss: 0.317836 [mini-batch 200 / 859]\n",
      "loss: 0.247340 [mini-batch 300 / 859]\n",
      "loss: 0.401124 [mini-batch 400 / 859]\n",
      "loss: 0.414253 [mini-batch 500 / 859]\n",
      "loss: 0.380585 [mini-batch 600 / 859]\n",
      "loss: 0.619642 [mini-batch 700 / 859]\n",
      "loss: 0.458937 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.1%, Avg loss: 0.426398\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.433843 [mini-batch 0 / 859]\n",
      "loss: 0.433709 [mini-batch 100 / 859]\n",
      "loss: 0.388128 [mini-batch 200 / 859]\n",
      "loss: 0.369368 [mini-batch 300 / 859]\n",
      "loss: 0.294666 [mini-batch 400 / 859]\n",
      "loss: 0.336159 [mini-batch 500 / 859]\n",
      "loss: 0.346572 [mini-batch 600 / 859]\n",
      "loss: 0.500009 [mini-batch 700 / 859]\n",
      "loss: 0.617540 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.4%, Avg loss: 0.412305\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.261796 [mini-batch 0 / 859]\n",
      "loss: 0.304770 [mini-batch 100 / 859]\n",
      "loss: 0.363100 [mini-batch 200 / 859]\n",
      "loss: 0.403570 [mini-batch 300 / 859]\n",
      "loss: 0.256445 [mini-batch 400 / 859]\n",
      "loss: 0.337816 [mini-batch 500 / 859]\n",
      "loss: 0.257729 [mini-batch 600 / 859]\n",
      "loss: 0.366765 [mini-batch 700 / 859]\n",
      "loss: 0.446162 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 05:13:36,925] Trial 14 finished with value: 0.8568 and parameters: {'learning rate': 0.0004883338500567561, 'L1 lambda': 0.010560939489270891}. Best is trial 13 with value: 0.8614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 85.7%, Avg loss: 0.403761\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 5.7%, Avg loss: 7.135423\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.560624 [mini-batch 0 / 859]\n",
      "loss: 0.809528 [mini-batch 100 / 859]\n",
      "loss: 0.576846 [mini-batch 200 / 859]\n",
      "loss: 0.603767 [mini-batch 300 / 859]\n",
      "loss: 0.378011 [mini-batch 400 / 859]\n",
      "loss: 0.544955 [mini-batch 500 / 859]\n",
      "loss: 0.475658 [mini-batch 600 / 859]\n",
      "loss: 0.304378 [mini-batch 700 / 859]\n",
      "loss: 0.449879 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.1%, Avg loss: 0.472605\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.425025 [mini-batch 0 / 859]\n",
      "loss: 0.542495 [mini-batch 100 / 859]\n",
      "loss: 0.344247 [mini-batch 200 / 859]\n",
      "loss: 0.313192 [mini-batch 300 / 859]\n",
      "loss: 0.356228 [mini-batch 400 / 859]\n",
      "loss: 0.335334 [mini-batch 500 / 859]\n",
      "loss: 0.370790 [mini-batch 600 / 859]\n",
      "loss: 0.559415 [mini-batch 700 / 859]\n",
      "loss: 0.564212 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.3%, Avg loss: 0.432540\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.295751 [mini-batch 0 / 859]\n",
      "loss: 0.389867 [mini-batch 100 / 859]\n",
      "loss: 0.556896 [mini-batch 200 / 859]\n",
      "loss: 0.478940 [mini-batch 300 / 859]\n",
      "loss: 0.342202 [mini-batch 400 / 859]\n",
      "loss: 0.512615 [mini-batch 500 / 859]\n",
      "loss: 0.470403 [mini-batch 600 / 859]\n",
      "loss: 0.469325 [mini-batch 700 / 859]\n",
      "loss: 0.391254 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.4%, Avg loss: 0.406989\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.374130 [mini-batch 0 / 859]\n",
      "loss: 0.342968 [mini-batch 100 / 859]\n",
      "loss: 0.409399 [mini-batch 200 / 859]\n",
      "loss: 0.347182 [mini-batch 300 / 859]\n",
      "loss: 0.495915 [mini-batch 400 / 859]\n",
      "loss: 0.313185 [mini-batch 500 / 859]\n",
      "loss: 0.333304 [mini-batch 600 / 859]\n",
      "loss: 0.282420 [mini-batch 700 / 859]\n",
      "loss: 0.290721 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.7%, Avg loss: 0.439581\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.571671 [mini-batch 0 / 859]\n",
      "loss: 0.386940 [mini-batch 100 / 859]\n",
      "loss: 0.303622 [mini-batch 200 / 859]\n",
      "loss: 0.608876 [mini-batch 300 / 859]\n",
      "loss: 0.390327 [mini-batch 400 / 859]\n",
      "loss: 0.279238 [mini-batch 500 / 859]\n",
      "loss: 0.319824 [mini-batch 600 / 859]\n",
      "loss: 0.453711 [mini-batch 700 / 859]\n",
      "loss: 0.462288 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 05:55:07,254] Trial 15 finished with value: 0.8372 and parameters: {'learning rate': 0.0009577358755908258, 'L1 lambda': 0.011445838974255135}. Best is trial 13 with value: 0.8614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 83.7%, Avg loss: 0.438749\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 11.4%, Avg loss: 7.785334\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.844865 [mini-batch 0 / 859]\n",
      "loss: 0.597304 [mini-batch 100 / 859]\n",
      "loss: 0.463335 [mini-batch 200 / 859]\n",
      "loss: 0.610277 [mini-batch 300 / 859]\n",
      "loss: 0.497698 [mini-batch 400 / 859]\n",
      "loss: 0.468068 [mini-batch 500 / 859]\n",
      "loss: 0.540269 [mini-batch 600 / 859]\n",
      "loss: 0.414265 [mini-batch 700 / 859]\n",
      "loss: 0.363691 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.4%, Avg loss: 0.506668\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.337850 [mini-batch 0 / 859]\n",
      "loss: 0.382137 [mini-batch 100 / 859]\n",
      "loss: 0.353299 [mini-batch 200 / 859]\n",
      "loss: 0.302129 [mini-batch 300 / 859]\n",
      "loss: 0.321095 [mini-batch 400 / 859]\n",
      "loss: 0.350428 [mini-batch 500 / 859]\n",
      "loss: 0.316650 [mini-batch 600 / 859]\n",
      "loss: 0.409036 [mini-batch 700 / 859]\n",
      "loss: 0.767042 [mini-batch 800 / 859]\n",
      "==> Accuracy: 79.3%, Avg loss: 0.576772\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.917564 [mini-batch 0 / 859]\n",
      "loss: 0.435996 [mini-batch 100 / 859]\n",
      "loss: 0.331301 [mini-batch 200 / 859]\n",
      "loss: 0.301079 [mini-batch 300 / 859]\n",
      "loss: 0.597815 [mini-batch 400 / 859]\n",
      "loss: 0.406079 [mini-batch 500 / 859]\n",
      "loss: 0.388720 [mini-batch 600 / 859]\n",
      "loss: 0.289436 [mini-batch 700 / 859]\n",
      "loss: 0.495628 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.4%, Avg loss: 0.439606\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.404294 [mini-batch 0 / 859]\n",
      "loss: 0.477202 [mini-batch 100 / 859]\n",
      "loss: 0.330011 [mini-batch 200 / 859]\n",
      "loss: 0.323827 [mini-batch 300 / 859]\n",
      "loss: 0.323890 [mini-batch 400 / 859]\n",
      "loss: 0.501283 [mini-batch 500 / 859]\n",
      "loss: 0.574373 [mini-batch 600 / 859]\n",
      "loss: 0.403935 [mini-batch 700 / 859]\n",
      "loss: 0.539548 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.5%, Avg loss: 0.416294\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.387110 [mini-batch 0 / 859]\n",
      "loss: 0.278653 [mini-batch 100 / 859]\n",
      "loss: 0.347722 [mini-batch 200 / 859]\n",
      "loss: 0.520771 [mini-batch 300 / 859]\n",
      "loss: 0.296565 [mini-batch 400 / 859]\n",
      "loss: 0.344025 [mini-batch 500 / 859]\n",
      "loss: 0.395474 [mini-batch 600 / 859]\n",
      "loss: 0.338339 [mini-batch 700 / 859]\n",
      "loss: 0.440209 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 06:36:18,935] Trial 16 finished with value: 0.8506 and parameters: {'learning rate': 0.0005112913433202883, 'L1 lambda': 0.011243497283883158}. Best is trial 13 with value: 0.8614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 85.1%, Avg loss: 0.412777\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 10.2%, Avg loss: 8.245626\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 8.899866 [mini-batch 0 / 859]\n",
      "loss: 0.732414 [mini-batch 100 / 859]\n",
      "loss: 0.433427 [mini-batch 200 / 859]\n",
      "loss: 0.595703 [mini-batch 300 / 859]\n",
      "loss: 0.539365 [mini-batch 400 / 859]\n",
      "loss: 0.619575 [mini-batch 500 / 859]\n",
      "loss: 0.522763 [mini-batch 600 / 859]\n",
      "loss: 0.800606 [mini-batch 700 / 859]\n",
      "loss: 0.372603 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.7%, Avg loss: 0.488949\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.514041 [mini-batch 0 / 859]\n",
      "loss: 0.485837 [mini-batch 100 / 859]\n",
      "loss: 0.403733 [mini-batch 200 / 859]\n",
      "loss: 0.416243 [mini-batch 300 / 859]\n",
      "loss: 0.630200 [mini-batch 400 / 859]\n",
      "loss: 0.410541 [mini-batch 500 / 859]\n",
      "loss: 0.410976 [mini-batch 600 / 859]\n",
      "loss: 0.493268 [mini-batch 700 / 859]\n",
      "loss: 0.438542 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.2%, Avg loss: 0.444766\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.434723 [mini-batch 0 / 859]\n",
      "loss: 0.256217 [mini-batch 100 / 859]\n",
      "loss: 0.358941 [mini-batch 200 / 859]\n",
      "loss: 0.368106 [mini-batch 300 / 859]\n",
      "loss: 0.844941 [mini-batch 400 / 859]\n",
      "loss: 0.429434 [mini-batch 500 / 859]\n",
      "loss: 0.382973 [mini-batch 600 / 859]\n",
      "loss: 0.491444 [mini-batch 700 / 859]\n",
      "loss: 0.248953 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.6%, Avg loss: 0.445653\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.372090 [mini-batch 0 / 859]\n",
      "loss: 0.376986 [mini-batch 100 / 859]\n",
      "loss: 0.236223 [mini-batch 200 / 859]\n",
      "loss: 0.593320 [mini-batch 300 / 859]\n",
      "loss: 0.452302 [mini-batch 400 / 859]\n",
      "loss: 0.453023 [mini-batch 500 / 859]\n",
      "loss: 0.500959 [mini-batch 600 / 859]\n",
      "loss: 0.417419 [mini-batch 700 / 859]\n",
      "loss: 0.487688 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.0%, Avg loss: 0.431076\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.529395 [mini-batch 0 / 859]\n",
      "loss: 0.286223 [mini-batch 100 / 859]\n",
      "loss: 0.518496 [mini-batch 200 / 859]\n",
      "loss: 0.331679 [mini-batch 300 / 859]\n",
      "loss: 0.565102 [mini-batch 400 / 859]\n",
      "loss: 0.237032 [mini-batch 500 / 859]\n",
      "loss: 0.435732 [mini-batch 600 / 859]\n",
      "loss: 0.422618 [mini-batch 700 / 859]\n",
      "loss: 0.628574 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 07:17:22,289] Trial 17 finished with value: 0.8614 and parameters: {'learning rate': 0.0005682110131058529, 'L1 lambda': 0.03280029715390454}. Best is trial 13 with value: 0.8614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 86.1%, Avg loss: 0.395244\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 12.3%, Avg loss: 6.059423\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 5.997901 [mini-batch 0 / 859]\n",
      "loss: 0.746360 [mini-batch 100 / 859]\n",
      "loss: 0.547201 [mini-batch 200 / 859]\n",
      "loss: 0.724649 [mini-batch 300 / 859]\n",
      "loss: 0.578724 [mini-batch 400 / 859]\n",
      "loss: 0.520932 [mini-batch 500 / 859]\n",
      "loss: 0.459739 [mini-batch 600 / 859]\n",
      "loss: 0.601075 [mini-batch 700 / 859]\n",
      "loss: 0.493387 [mini-batch 800 / 859]\n",
      "==> Accuracy: 79.6%, Avg loss: 0.549453\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.410730 [mini-batch 0 / 859]\n",
      "loss: 0.492022 [mini-batch 100 / 859]\n",
      "loss: 0.411374 [mini-batch 200 / 859]\n",
      "loss: 0.368989 [mini-batch 300 / 859]\n",
      "loss: 0.420517 [mini-batch 400 / 859]\n",
      "loss: 0.489375 [mini-batch 500 / 859]\n",
      "loss: 0.438578 [mini-batch 600 / 859]\n",
      "loss: 0.401202 [mini-batch 700 / 859]\n",
      "loss: 0.439688 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.8%, Avg loss: 0.462382\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.574921 [mini-batch 0 / 859]\n",
      "loss: 0.407441 [mini-batch 100 / 859]\n",
      "loss: 0.455795 [mini-batch 200 / 859]\n",
      "loss: 0.419776 [mini-batch 300 / 859]\n",
      "loss: 0.353202 [mini-batch 400 / 859]\n",
      "loss: 0.499052 [mini-batch 500 / 859]\n",
      "loss: 0.414876 [mini-batch 600 / 859]\n",
      "loss: 0.456818 [mini-batch 700 / 859]\n",
      "loss: 0.413293 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.4%, Avg loss: 0.425852\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.340136 [mini-batch 0 / 859]\n",
      "loss: 0.370403 [mini-batch 100 / 859]\n",
      "loss: 0.378086 [mini-batch 200 / 859]\n",
      "loss: 0.372315 [mini-batch 300 / 859]\n",
      "loss: 0.479106 [mini-batch 400 / 859]\n",
      "loss: 0.306134 [mini-batch 500 / 859]\n",
      "loss: 0.395451 [mini-batch 600 / 859]\n",
      "loss: 0.429172 [mini-batch 700 / 859]\n",
      "loss: 0.374265 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.7%, Avg loss: 0.401395\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.392390 [mini-batch 0 / 859]\n",
      "loss: 0.434836 [mini-batch 100 / 859]\n",
      "loss: 0.647948 [mini-batch 200 / 859]\n",
      "loss: 0.428576 [mini-batch 300 / 859]\n",
      "loss: 0.390103 [mini-batch 400 / 859]\n",
      "loss: 0.364455 [mini-batch 500 / 859]\n",
      "loss: 0.311191 [mini-batch 600 / 859]\n",
      "loss: 0.365755 [mini-batch 700 / 859]\n",
      "loss: 0.275303 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 07:58:50,437] Trial 18 finished with value: 0.851 and parameters: {'learning rate': 0.0006647928087792768, 'L1 lambda': 0.02989893171437926}. Best is trial 13 with value: 0.8614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 85.1%, Avg loss: 0.400170\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 8.8%, Avg loss: 10.737887\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 11.012549 [mini-batch 0 / 859]\n",
      "loss: 1.323095 [mini-batch 100 / 859]\n",
      "loss: 0.756378 [mini-batch 200 / 859]\n",
      "loss: 0.767382 [mini-batch 300 / 859]\n",
      "loss: 0.654166 [mini-batch 400 / 859]\n",
      "loss: 0.762742 [mini-batch 500 / 859]\n",
      "loss: 0.911947 [mini-batch 600 / 859]\n",
      "loss: 0.444421 [mini-batch 700 / 859]\n",
      "loss: 0.648062 [mini-batch 800 / 859]\n",
      "==> Accuracy: 77.8%, Avg loss: 0.643568\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.665605 [mini-batch 0 / 859]\n",
      "loss: 0.618925 [mini-batch 100 / 859]\n",
      "loss: 0.464664 [mini-batch 200 / 859]\n",
      "loss: 0.430840 [mini-batch 300 / 859]\n",
      "loss: 0.548159 [mini-batch 400 / 859]\n",
      "loss: 0.427944 [mini-batch 500 / 859]\n",
      "loss: 0.558204 [mini-batch 600 / 859]\n",
      "loss: 0.605002 [mini-batch 700 / 859]\n",
      "loss: 0.635926 [mini-batch 800 / 859]\n",
      "==> Accuracy: 79.1%, Avg loss: 0.579705\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.538439 [mini-batch 0 / 859]\n",
      "loss: 0.688029 [mini-batch 100 / 859]\n",
      "loss: 0.480406 [mini-batch 200 / 859]\n",
      "loss: 0.397620 [mini-batch 300 / 859]\n",
      "loss: 0.380522 [mini-batch 400 / 859]\n",
      "loss: 0.710620 [mini-batch 500 / 859]\n",
      "loss: 0.800658 [mini-batch 600 / 859]\n",
      "loss: 0.449858 [mini-batch 700 / 859]\n",
      "loss: 0.352119 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.0%, Avg loss: 0.539333\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.380899 [mini-batch 0 / 859]\n",
      "loss: 0.509049 [mini-batch 100 / 859]\n",
      "loss: 0.564608 [mini-batch 200 / 859]\n",
      "loss: 0.442730 [mini-batch 300 / 859]\n",
      "loss: 0.596194 [mini-batch 400 / 859]\n",
      "loss: 0.601548 [mini-batch 500 / 859]\n",
      "loss: 0.574651 [mini-batch 600 / 859]\n",
      "loss: 0.483973 [mini-batch 700 / 859]\n",
      "loss: 0.548955 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.0%, Avg loss: 0.516785\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.546575 [mini-batch 0 / 859]\n",
      "loss: 0.714422 [mini-batch 100 / 859]\n",
      "loss: 0.582080 [mini-batch 200 / 859]\n",
      "loss: 0.501072 [mini-batch 300 / 859]\n",
      "loss: 0.521398 [mini-batch 400 / 859]\n",
      "loss: 0.413005 [mini-batch 500 / 859]\n",
      "loss: 0.501879 [mini-batch 600 / 859]\n",
      "loss: 0.368563 [mini-batch 700 / 859]\n",
      "loss: 0.586099 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 08:40:58,056] Trial 19 finished with value: 0.8288 and parameters: {'learning rate': 7.31826339269652e-05, 'L1 lambda': 0.033523375323614185}. Best is trial 13 with value: 0.8614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 82.9%, Avg loss: 0.499429\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 13.7%, Avg loss: 5.158815\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 4.827010 [mini-batch 0 / 859]\n",
      "loss: 0.702271 [mini-batch 100 / 859]\n",
      "loss: 1.042210 [mini-batch 200 / 859]\n",
      "loss: 0.870425 [mini-batch 300 / 859]\n",
      "loss: 0.617414 [mini-batch 400 / 859]\n",
      "loss: 0.663946 [mini-batch 500 / 859]\n",
      "loss: 0.474360 [mini-batch 600 / 859]\n",
      "loss: 0.851314 [mini-batch 700 / 859]\n",
      "loss: 0.623632 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.0%, Avg loss: 0.549537\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.400558 [mini-batch 0 / 859]\n",
      "loss: 0.369093 [mini-batch 100 / 859]\n",
      "loss: 0.547290 [mini-batch 200 / 859]\n",
      "loss: 0.684507 [mini-batch 300 / 859]\n",
      "loss: 0.501623 [mini-batch 400 / 859]\n",
      "loss: 0.509881 [mini-batch 500 / 859]\n",
      "loss: 0.402682 [mini-batch 600 / 859]\n",
      "loss: 0.562854 [mini-batch 700 / 859]\n",
      "loss: 0.491692 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.4%, Avg loss: 0.504460\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.540837 [mini-batch 0 / 859]\n",
      "loss: 0.621843 [mini-batch 100 / 859]\n",
      "loss: 0.462173 [mini-batch 200 / 859]\n",
      "loss: 0.657393 [mini-batch 300 / 859]\n",
      "loss: 0.584585 [mini-batch 400 / 859]\n",
      "loss: 0.564237 [mini-batch 500 / 859]\n",
      "loss: 0.371832 [mini-batch 600 / 859]\n",
      "loss: 0.584940 [mini-batch 700 / 859]\n",
      "loss: 0.461882 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.5%, Avg loss: 0.467347\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.395666 [mini-batch 0 / 859]\n",
      "loss: 0.378597 [mini-batch 100 / 859]\n",
      "loss: 0.548538 [mini-batch 200 / 859]\n",
      "loss: 0.612984 [mini-batch 300 / 859]\n",
      "loss: 0.485206 [mini-batch 400 / 859]\n",
      "loss: 0.265693 [mini-batch 500 / 859]\n",
      "loss: 0.348699 [mini-batch 600 / 859]\n",
      "loss: 0.402772 [mini-batch 700 / 859]\n",
      "loss: 0.849061 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.1%, Avg loss: 0.448113\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.362394 [mini-batch 0 / 859]\n",
      "loss: 0.623844 [mini-batch 100 / 859]\n",
      "loss: 0.332253 [mini-batch 200 / 859]\n",
      "loss: 0.344746 [mini-batch 300 / 859]\n",
      "loss: 0.357535 [mini-batch 400 / 859]\n",
      "loss: 0.557729 [mini-batch 500 / 859]\n",
      "loss: 0.377501 [mini-batch 600 / 859]\n",
      "loss: 0.346443 [mini-batch 700 / 859]\n",
      "loss: 0.300039 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 09:22:37,494] Trial 20 finished with value: 0.8488 and parameters: {'learning rate': 0.00019319183446876565, 'L1 lambda': 0.04814086670653351}. Best is trial 13 with value: 0.8614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 84.9%, Avg loss: 0.427604\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 10.7%, Avg loss: 7.236620\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 8.266877 [mini-batch 0 / 859]\n",
      "loss: 0.729457 [mini-batch 100 / 859]\n",
      "loss: 0.826829 [mini-batch 200 / 859]\n",
      "loss: 0.786932 [mini-batch 300 / 859]\n",
      "loss: 0.527818 [mini-batch 400 / 859]\n",
      "loss: 0.640558 [mini-batch 500 / 859]\n",
      "loss: 0.488798 [mini-batch 600 / 859]\n",
      "loss: 0.681294 [mini-batch 700 / 859]\n",
      "loss: 0.424786 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.6%, Avg loss: 0.497885\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.476494 [mini-batch 0 / 859]\n",
      "loss: 0.333769 [mini-batch 100 / 859]\n",
      "loss: 0.637873 [mini-batch 200 / 859]\n",
      "loss: 0.480767 [mini-batch 300 / 859]\n",
      "loss: 0.478855 [mini-batch 400 / 859]\n",
      "loss: 0.777539 [mini-batch 500 / 859]\n",
      "loss: 0.549290 [mini-batch 600 / 859]\n",
      "loss: 0.425081 [mini-batch 700 / 859]\n",
      "loss: 0.515532 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.3%, Avg loss: 0.511576\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.419346 [mini-batch 0 / 859]\n",
      "loss: 0.434606 [mini-batch 100 / 859]\n",
      "loss: 0.462928 [mini-batch 200 / 859]\n",
      "loss: 0.508402 [mini-batch 300 / 859]\n",
      "loss: 0.604731 [mini-batch 400 / 859]\n",
      "loss: 0.420026 [mini-batch 500 / 859]\n",
      "loss: 0.435241 [mini-batch 600 / 859]\n",
      "loss: 0.316381 [mini-batch 700 / 859]\n",
      "loss: 0.430198 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.4%, Avg loss: 0.433088\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.323142 [mini-batch 0 / 859]\n",
      "loss: 0.428864 [mini-batch 100 / 859]\n",
      "loss: 0.351459 [mini-batch 200 / 859]\n",
      "loss: 0.290301 [mini-batch 300 / 859]\n",
      "loss: 0.397890 [mini-batch 400 / 859]\n",
      "loss: 0.292363 [mini-batch 500 / 859]\n",
      "loss: 0.361179 [mini-batch 600 / 859]\n",
      "loss: 0.379136 [mini-batch 700 / 859]\n",
      "loss: 0.355840 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.3%, Avg loss: 0.432124\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.536079 [mini-batch 0 / 859]\n",
      "loss: 0.428346 [mini-batch 100 / 859]\n",
      "loss: 0.637848 [mini-batch 200 / 859]\n",
      "loss: 0.351512 [mini-batch 300 / 859]\n",
      "loss: 0.510055 [mini-batch 400 / 859]\n",
      "loss: 0.312049 [mini-batch 500 / 859]\n",
      "loss: 0.768882 [mini-batch 600 / 859]\n",
      "loss: 0.410066 [mini-batch 700 / 859]\n",
      "loss: 0.287331 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 10:05:01,736] Trial 21 finished with value: 0.8612 and parameters: {'learning rate': 0.00042635087728591886, 'L1 lambda': 0.015633580148084223}. Best is trial 13 with value: 0.8614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 86.1%, Avg loss: 0.390881\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 15.3%, Avg loss: 6.588694\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 5.977013 [mini-batch 0 / 859]\n",
      "loss: 0.649204 [mini-batch 100 / 859]\n",
      "loss: 0.545501 [mini-batch 200 / 859]\n",
      "loss: 0.902558 [mini-batch 300 / 859]\n",
      "loss: 0.786658 [mini-batch 400 / 859]\n",
      "loss: 0.576461 [mini-batch 500 / 859]\n",
      "loss: 0.394667 [mini-batch 600 / 859]\n",
      "loss: 0.578750 [mini-batch 700 / 859]\n",
      "loss: 0.526283 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.7%, Avg loss: 0.537085\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.360105 [mini-batch 0 / 859]\n",
      "loss: 0.444878 [mini-batch 100 / 859]\n",
      "loss: 0.477410 [mini-batch 200 / 859]\n",
      "loss: 0.711136 [mini-batch 300 / 859]\n",
      "loss: 0.536984 [mini-batch 400 / 859]\n",
      "loss: 0.365677 [mini-batch 500 / 859]\n",
      "loss: 0.509276 [mini-batch 600 / 859]\n",
      "loss: 0.567063 [mini-batch 700 / 859]\n",
      "loss: 0.378564 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.6%, Avg loss: 0.507181\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.419232 [mini-batch 0 / 859]\n",
      "loss: 0.353495 [mini-batch 100 / 859]\n",
      "loss: 0.771254 [mini-batch 200 / 859]\n",
      "loss: 0.299947 [mini-batch 300 / 859]\n",
      "loss: 0.408011 [mini-batch 400 / 859]\n",
      "loss: 0.511759 [mini-batch 500 / 859]\n",
      "loss: 0.405200 [mini-batch 600 / 859]\n",
      "loss: 0.441942 [mini-batch 700 / 859]\n",
      "loss: 0.410973 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.4%, Avg loss: 0.446335\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.331134 [mini-batch 0 / 859]\n",
      "loss: 0.382663 [mini-batch 100 / 859]\n",
      "loss: 0.345894 [mini-batch 200 / 859]\n",
      "loss: 0.475784 [mini-batch 300 / 859]\n",
      "loss: 0.409393 [mini-batch 400 / 859]\n",
      "loss: 0.365832 [mini-batch 500 / 859]\n",
      "loss: 0.602401 [mini-batch 600 / 859]\n",
      "loss: 0.470557 [mini-batch 700 / 859]\n",
      "loss: 0.575918 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.3%, Avg loss: 0.422707\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.558927 [mini-batch 0 / 859]\n",
      "loss: 0.224170 [mini-batch 100 / 859]\n",
      "loss: 0.467575 [mini-batch 200 / 859]\n",
      "loss: 0.491267 [mini-batch 300 / 859]\n",
      "loss: 0.431836 [mini-batch 400 / 859]\n",
      "loss: 0.252871 [mini-batch 500 / 859]\n",
      "loss: 0.272617 [mini-batch 600 / 859]\n",
      "loss: 0.288789 [mini-batch 700 / 859]\n",
      "loss: 0.609686 [mini-batch 800 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-25 10:46:04,633] Trial 22 finished with value: 0.848 and parameters: {'learning rate': 0.0003326412298284213, 'L1 lambda': 0.019208842204589717}. Best is trial 13 with value: 0.8614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Accuracy: 84.8%, Avg loss: 0.422792\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 2.3%, Avg loss: 7.991079\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.948682 [mini-batch 0 / 859]\n",
      "loss: 0.791534 [mini-batch 100 / 859]\n",
      "loss: 0.774691 [mini-batch 200 / 859]\n",
      "loss: 0.549950 [mini-batch 300 / 859]\n",
      "loss: 0.745120 [mini-batch 400 / 859]\n",
      "loss: 0.645032 [mini-batch 500 / 859]\n",
      "loss: 0.482954 [mini-batch 600 / 859]\n",
      "loss: 0.390980 [mini-batch 700 / 859]\n",
      "loss: 0.555356 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.1%, Avg loss: 0.492824\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.570364 [mini-batch 0 / 859]\n",
      "loss: 0.688774 [mini-batch 100 / 859]\n",
      "loss: 0.589898 [mini-batch 200 / 859]\n",
      "loss: 0.506521 [mini-batch 300 / 859]\n",
      "loss: 0.384402 [mini-batch 400 / 859]\n",
      "loss: 0.635170 [mini-batch 500 / 859]\n",
      "loss: 0.440262 [mini-batch 600 / 859]\n",
      "loss: 0.384721 [mini-batch 700 / 859]\n",
      "loss: 0.533046 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.7%, Avg loss: 0.431717\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.456339 [mini-batch 0 / 859]\n",
      "loss: 0.433658 [mini-batch 100 / 859]\n",
      "loss: 0.400467 [mini-batch 200 / 859]\n",
      "loss: 0.381122 [mini-batch 300 / 859]\n",
      "loss: 0.336128 [mini-batch 400 / 859]\n",
      "loss: 0.433595 [mini-batch 500 / 859]\n",
      "loss: 0.645121 [mini-batch 600 / 859]\n",
      "loss: 0.369693 [mini-batch 700 / 859]\n",
      "loss: 0.419010 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.4%, Avg loss: 0.424872\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.509934 [mini-batch 0 / 859]\n",
      "loss: 0.467108 [mini-batch 100 / 859]\n",
      "loss: 0.379467 [mini-batch 200 / 859]\n",
      "loss: 0.492359 [mini-batch 300 / 859]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-06-25 11:14:36,818] Trial 23 failed with parameters: {'learning rate': 0.0007261573207076086, 'L1 lambda': 0.060698207315206865} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guille/venv/torch/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_63639/4099157515.py\", line 11, in objective\n",
      "    accuracy, _ = nn.train(train_data, validation_data)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guille/Documents/fashion_mnist_nn/regularization/sgd_L1.py\", line 125, in train\n",
      "    sum_loss += self.calc_gradients(x, y)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guille/Documents/fashion_mnist_nn/regularization/sgd_L1.py\", line 83, in calc_gradients\n",
      "    self.forward(x)\n",
      "  File \"/home/guille/Documents/fashion_mnist_nn/regularization/sgd_L1.py\", line 62, in forward\n",
      "    self.a[l] = np.maximum(0, self.z[l])\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-25 11:14:36,840] Trial 23 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/torch/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/torch/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/venv/torch/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/venv/torch/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/venv/torch/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      3\u001b[0m L1_lambda \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL1 lambda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;241m10\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(\n\u001b[1;32m      5\u001b[0m     [\u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m10\u001b[39m], \u001b[38;5;66;03m# layers size\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     learning_rate,               \u001b[38;5;66;03m# learning rate\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m5\u001b[39m                            \u001b[38;5;66;03m# training epochs\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m accuracy, _ \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/fashion_mnist_nn/regularization/sgd_L1.py:125\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[0;34m(self, train_data, test_data)\u001b[0m\n\u001b[1;32m    122\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(mini_batch)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m mini_batch:\n\u001b[0;32m--> 125\u001b[0m     sum_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_nabla_z[l] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnabla_z[l]\n",
      "File \u001b[0;32m~/Documents/fashion_mnist_nn/regularization/sgd_L1.py:83\u001b[0m, in \u001b[0;36mNeuralNetwork.calc_gradients\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y):\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# Last layer\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/fashion_mnist_nn/regularization/sgd_L1.py:62\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz[l] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[l] \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma[l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases[l]\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma[l] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Last layer\u001b[39;00m\n\u001b[1;32m     64\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd20f3a-da7f-4a2b-8120-d7ed1554de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1e9ed-95e3-4238-86fb-7056ed57120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ov.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f709be-897f-4c06-bd9d-ea89dbb7e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ov.plot_contour(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
