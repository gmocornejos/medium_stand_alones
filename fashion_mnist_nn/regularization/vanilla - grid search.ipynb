{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269f83d4-70d4-40dc-b3d3-2a99c6223eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sgd_vanilla import NeuralNetwork\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "with open(\"../data/train_data.pkl\", \"rb\") as train_file:\n",
    "    train_data = pickle.load(train_file)\n",
    "\n",
    "rng.shuffle(train_data)\n",
    "validation_data = train_data[:5000]\n",
    "train_data = train_data[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8243c9-5aeb-48f0-b707-d19614596186",
   "metadata": {},
   "source": [
    "### Upper bound\n",
    "\n",
    "At $learning~rate = 1e^{-2}$, gradients go to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50b8b7d-b461-4aed-a254-2660b4832788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-train stats\n",
      "==> Accuracy: 6.5%, Avg loss: 2.538705\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 2.584022 [mini-batch 0 / 859]\n",
      "loss: 0.863439 [mini-batch 100 / 859]\n",
      "loss: 0.631710 [mini-batch 200 / 859]\n",
      "loss: 0.785530 [mini-batch 300 / 859]\n",
      "loss: 0.714624 [mini-batch 400 / 859]\n",
      "loss: 0.496941 [mini-batch 500 / 859]\n",
      "loss: 0.616181 [mini-batch 600 / 859]\n",
      "loss: 0.445545 [mini-batch 700 / 859]\n",
      "loss: 0.606924 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.6%, Avg loss: 0.528947\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.537935 [mini-batch 0 / 859]\n",
      "loss: 0.521437 [mini-batch 100 / 859]\n",
      "loss: 0.519006 [mini-batch 200 / 859]\n",
      "loss: 0.484267 [mini-batch 300 / 859]\n",
      "loss: 0.474799 [mini-batch 400 / 859]\n",
      "loss: 0.370711 [mini-batch 500 / 859]\n",
      "loss: 0.381911 [mini-batch 600 / 859]\n",
      "loss: 0.492784 [mini-batch 700 / 859]\n",
      "loss: 0.457213 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.7%, Avg loss: 0.497764\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0652, 0.8158, 0.8268],\n",
       " [2.53870462536722, 0.5289466260515856, 0.49776406215165825])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get upper bound\n",
    "\n",
    "nn = NeuralNetwork(\n",
    "    [28*28, 1024, 512, 256, 128, 64, 10], # layers size\n",
    "    1e-3,                           # learning rate\n",
    "    64,                            # mini batch size\n",
    "    2                               # training epochs\n",
    ")\n",
    "\n",
    "nn.train(train_data, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a65dc7-558b-4b62-aef2-b70a7fec5903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-train stats\n",
      "==> Accuracy: 8.5%, Avg loss: 5.482983\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 5.080401 [mini-batch 0 / 859]\n",
      "loss: 4.803390 [mini-batch 100 / 859]\n",
      "loss: 4.253553 [mini-batch 200 / 859]\n",
      "loss: 4.118259 [mini-batch 300 / 859]\n",
      "loss: 3.572328 [mini-batch 400 / 859]\n",
      "loss: 3.856593 [mini-batch 500 / 859]\n",
      "loss: 3.666855 [mini-batch 600 / 859]\n",
      "loss: 3.464669 [mini-batch 700 / 859]\n",
      "loss: 3.280781 [mini-batch 800 / 859]\n",
      "==> Accuracy: 11.4%, Avg loss: 3.389511\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 3.471739 [mini-batch 0 / 859]\n",
      "loss: 3.301901 [mini-batch 100 / 859]\n",
      "loss: 3.218524 [mini-batch 200 / 859]\n",
      "loss: 3.006152 [mini-batch 300 / 859]\n",
      "loss: 3.236323 [mini-batch 400 / 859]\n",
      "loss: 3.306492 [mini-batch 500 / 859]\n",
      "loss: 2.767461 [mini-batch 600 / 859]\n",
      "loss: 3.105749 [mini-batch 700 / 859]\n",
      "loss: 3.063544 [mini-batch 800 / 859]\n",
      "==> Accuracy: 18.8%, Avg loss: 2.830173\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 2.912947 [mini-batch 0 / 859]\n",
      "loss: 2.818730 [mini-batch 100 / 859]\n",
      "loss: 2.946768 [mini-batch 200 / 859]\n",
      "loss: 2.561483 [mini-batch 300 / 859]\n",
      "loss: 2.057950 [mini-batch 400 / 859]\n",
      "loss: 2.516538 [mini-batch 500 / 859]\n",
      "loss: 2.403839 [mini-batch 600 / 859]\n",
      "loss: 2.311450 [mini-batch 700 / 859]\n",
      "loss: 2.441723 [mini-batch 800 / 859]\n",
      "==> Accuracy: 26.5%, Avg loss: 2.441606\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 2.321741 [mini-batch 0 / 859]\n",
      "loss: 2.250432 [mini-batch 100 / 859]\n",
      "loss: 2.033774 [mini-batch 200 / 859]\n",
      "loss: 2.669966 [mini-batch 300 / 859]\n",
      "loss: 2.274846 [mini-batch 400 / 859]\n",
      "loss: 2.497701 [mini-batch 500 / 859]\n",
      "loss: 2.084756 [mini-batch 600 / 859]\n",
      "loss: 2.228472 [mini-batch 700 / 859]\n",
      "loss: 2.331754 [mini-batch 800 / 859]\n",
      "==> Accuracy: 33.0%, Avg loss: 2.172061\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 2.000353 [mini-batch 0 / 859]\n",
      "loss: 1.974388 [mini-batch 100 / 859]\n",
      "loss: 2.028022 [mini-batch 200 / 859]\n",
      "loss: 2.124037 [mini-batch 300 / 859]\n",
      "loss: 2.156122 [mini-batch 400 / 859]\n",
      "loss: 1.858584 [mini-batch 500 / 859]\n",
      "loss: 2.060724 [mini-batch 600 / 859]\n",
      "loss: 2.143711 [mini-batch 700 / 859]\n",
      "loss: 2.136934 [mini-batch 800 / 859]\n",
      "==> Accuracy: 37.8%, Avg loss: 1.980692\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 16.6%, Avg loss: 9.654682\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 11.352326 [mini-batch 0 / 859]\n",
      "loss: 6.486714 [mini-batch 100 / 859]\n",
      "loss: 5.552573 [mini-batch 200 / 859]\n",
      "loss: 3.902508 [mini-batch 300 / 859]\n",
      "loss: 4.051002 [mini-batch 400 / 859]\n",
      "loss: 3.409669 [mini-batch 500 / 859]\n",
      "loss: 3.245381 [mini-batch 600 / 859]\n",
      "loss: 2.616848 [mini-batch 700 / 859]\n",
      "loss: 3.018078 [mini-batch 800 / 859]\n",
      "==> Accuracy: 21.7%, Avg loss: 2.770725\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 3.075060 [mini-batch 0 / 859]\n",
      "loss: 2.572449 [mini-batch 100 / 859]\n",
      "loss: 2.586809 [mini-batch 200 / 859]\n",
      "loss: 2.371812 [mini-batch 300 / 859]\n",
      "loss: 2.432124 [mini-batch 400 / 859]\n",
      "loss: 2.391866 [mini-batch 500 / 859]\n",
      "loss: 2.299707 [mini-batch 600 / 859]\n",
      "loss: 2.179321 [mini-batch 700 / 859]\n",
      "loss: 2.388354 [mini-batch 800 / 859]\n",
      "==> Accuracy: 30.6%, Avg loss: 2.229448\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 2.010426 [mini-batch 0 / 859]\n",
      "loss: 2.390822 [mini-batch 100 / 859]\n",
      "loss: 2.574039 [mini-batch 200 / 859]\n",
      "loss: 2.237666 [mini-batch 300 / 859]\n",
      "loss: 2.379375 [mini-batch 400 / 859]\n",
      "loss: 2.293500 [mini-batch 500 / 859]\n",
      "loss: 1.879037 [mini-batch 600 / 859]\n",
      "loss: 1.787647 [mini-batch 700 / 859]\n",
      "loss: 1.788331 [mini-batch 800 / 859]\n",
      "==> Accuracy: 36.6%, Avg loss: 1.973476\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 1.784057 [mini-batch 0 / 859]\n",
      "loss: 2.227568 [mini-batch 100 / 859]\n",
      "loss: 2.171809 [mini-batch 200 / 859]\n",
      "loss: 1.723759 [mini-batch 300 / 859]\n",
      "loss: 1.687889 [mini-batch 400 / 859]\n",
      "loss: 2.054848 [mini-batch 500 / 859]\n",
      "loss: 1.626301 [mini-batch 600 / 859]\n",
      "loss: 1.624209 [mini-batch 700 / 859]\n",
      "loss: 2.018778 [mini-batch 800 / 859]\n",
      "==> Accuracy: 40.1%, Avg loss: 1.801410\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 1.813657 [mini-batch 0 / 859]\n",
      "loss: 1.903609 [mini-batch 100 / 859]\n",
      "loss: 1.397209 [mini-batch 200 / 859]\n",
      "loss: 1.756606 [mini-batch 300 / 859]\n",
      "loss: 1.852219 [mini-batch 400 / 859]\n",
      "loss: 1.483028 [mini-batch 500 / 859]\n",
      "loss: 1.641766 [mini-batch 600 / 859]\n",
      "loss: 1.646105 [mini-batch 700 / 859]\n",
      "loss: 1.613281 [mini-batch 800 / 859]\n",
      "==> Accuracy: 43.8%, Avg loss: 1.676978\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 10.6%, Avg loss: 10.803966\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 10.228290 [mini-batch 0 / 859]\n",
      "loss: 6.462909 [mini-batch 100 / 859]\n",
      "loss: 5.682165 [mini-batch 200 / 859]\n",
      "loss: 4.061781 [mini-batch 300 / 859]\n",
      "loss: 4.146102 [mini-batch 400 / 859]\n",
      "loss: 3.704408 [mini-batch 500 / 859]\n",
      "loss: 3.650892 [mini-batch 600 / 859]\n",
      "loss: 3.519813 [mini-batch 700 / 859]\n",
      "loss: 2.871044 [mini-batch 800 / 859]\n",
      "==> Accuracy: 20.0%, Avg loss: 3.128448\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 3.667129 [mini-batch 0 / 859]\n",
      "loss: 2.833891 [mini-batch 100 / 859]\n",
      "loss: 2.860005 [mini-batch 200 / 859]\n",
      "loss: 2.665069 [mini-batch 300 / 859]\n",
      "loss: 2.613755 [mini-batch 400 / 859]\n",
      "loss: 2.314544 [mini-batch 500 / 859]\n",
      "loss: 2.817782 [mini-batch 600 / 859]\n",
      "loss: 2.313326 [mini-batch 700 / 859]\n",
      "loss: 2.463993 [mini-batch 800 / 859]\n",
      "==> Accuracy: 31.7%, Avg loss: 2.377321\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 2.530399 [mini-batch 0 / 859]\n",
      "loss: 2.497099 [mini-batch 100 / 859]\n",
      "loss: 2.125847 [mini-batch 200 / 859]\n",
      "loss: 1.768552 [mini-batch 300 / 859]\n",
      "loss: 1.870262 [mini-batch 400 / 859]\n",
      "loss: 1.670070 [mini-batch 500 / 859]\n",
      "loss: 1.689391 [mini-batch 600 / 859]\n",
      "loss: 1.483785 [mini-batch 700 / 859]\n",
      "loss: 2.084255 [mini-batch 800 / 859]\n",
      "==> Accuracy: 37.8%, Avg loss: 2.039418\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 1.988743 [mini-batch 0 / 859]\n",
      "loss: 1.696605 [mini-batch 100 / 859]\n",
      "loss: 1.974693 [mini-batch 200 / 859]\n",
      "loss: 1.998585 [mini-batch 300 / 859]\n",
      "loss: 2.154597 [mini-batch 400 / 859]\n",
      "loss: 1.911509 [mini-batch 500 / 859]\n",
      "loss: 1.843820 [mini-batch 600 / 859]\n",
      "loss: 1.911443 [mini-batch 700 / 859]\n",
      "loss: 1.565555 [mini-batch 800 / 859]\n",
      "==> Accuracy: 42.2%, Avg loss: 1.855525\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 1.959316 [mini-batch 0 / 859]\n",
      "loss: 1.490866 [mini-batch 100 / 859]\n",
      "loss: 1.772516 [mini-batch 200 / 859]\n",
      "loss: 1.881687 [mini-batch 300 / 859]\n",
      "loss: 1.617832 [mini-batch 400 / 859]\n",
      "loss: 1.855936 [mini-batch 500 / 859]\n",
      "loss: 1.429539 [mini-batch 600 / 859]\n",
      "loss: 1.630432 [mini-batch 700 / 859]\n",
      "loss: 1.560823 [mini-batch 800 / 859]\n",
      "==> Accuracy: 46.0%, Avg loss: 1.728188\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 7.9%, Avg loss: 6.574976\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.835985 [mini-batch 0 / 859]\n",
      "loss: 3.931553 [mini-batch 100 / 859]\n",
      "loss: 4.023633 [mini-batch 200 / 859]\n",
      "loss: 3.474514 [mini-batch 300 / 859]\n",
      "loss: 3.054362 [mini-batch 400 / 859]\n",
      "loss: 3.082233 [mini-batch 500 / 859]\n",
      "loss: 2.822608 [mini-batch 600 / 859]\n",
      "loss: 2.579663 [mini-batch 700 / 859]\n",
      "loss: 2.788346 [mini-batch 800 / 859]\n",
      "==> Accuracy: 18.4%, Avg loss: 2.528529\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 2.462447 [mini-batch 0 / 859]\n",
      "loss: 2.467955 [mini-batch 100 / 859]\n",
      "loss: 2.742220 [mini-batch 200 / 859]\n",
      "loss: 2.359241 [mini-batch 300 / 859]\n",
      "loss: 2.467088 [mini-batch 400 / 859]\n",
      "loss: 2.138019 [mini-batch 500 / 859]\n",
      "loss: 2.027731 [mini-batch 600 / 859]\n",
      "loss: 2.503594 [mini-batch 700 / 859]\n",
      "loss: 1.912827 [mini-batch 800 / 859]\n",
      "==> Accuracy: 27.9%, Avg loss: 2.143861\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 2.193505 [mini-batch 0 / 859]\n",
      "loss: 2.241378 [mini-batch 100 / 859]\n",
      "loss: 1.997849 [mini-batch 200 / 859]\n",
      "loss: 2.122299 [mini-batch 300 / 859]\n",
      "loss: 2.126751 [mini-batch 400 / 859]\n",
      "loss: 1.815039 [mini-batch 500 / 859]\n",
      "loss: 1.974791 [mini-batch 600 / 859]\n",
      "loss: 2.047145 [mini-batch 700 / 859]\n",
      "loss: 1.820947 [mini-batch 800 / 859]\n",
      "==> Accuracy: 34.0%, Avg loss: 1.913490\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 1.969659 [mini-batch 0 / 859]\n",
      "loss: 1.687021 [mini-batch 100 / 859]\n",
      "loss: 2.011163 [mini-batch 200 / 859]\n",
      "loss: 1.746201 [mini-batch 300 / 859]\n",
      "loss: 1.672579 [mini-batch 400 / 859]\n",
      "loss: 1.860459 [mini-batch 500 / 859]\n",
      "loss: 1.785146 [mini-batch 600 / 859]\n",
      "loss: 1.961089 [mini-batch 700 / 859]\n",
      "loss: 1.624254 [mini-batch 800 / 859]\n",
      "==> Accuracy: 38.4%, Avg loss: 1.749401\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 1.719367 [mini-batch 0 / 859]\n",
      "loss: 1.467447 [mini-batch 100 / 859]\n",
      "loss: 1.734713 [mini-batch 200 / 859]\n",
      "loss: 1.431989 [mini-batch 300 / 859]\n",
      "loss: 1.576508 [mini-batch 400 / 859]\n",
      "loss: 1.792413 [mini-batch 500 / 859]\n",
      "loss: 1.328752 [mini-batch 600 / 859]\n",
      "loss: 1.622740 [mini-batch 700 / 859]\n",
      "loss: 1.556926 [mini-batch 800 / 859]\n",
      "==> Accuracy: 42.2%, Avg loss: 1.625438\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 9.7%, Avg loss: 7.226703\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 7.120528 [mini-batch 0 / 859]\n",
      "loss: 4.632929 [mini-batch 100 / 859]\n",
      "loss: 4.452793 [mini-batch 200 / 859]\n",
      "loss: 4.100642 [mini-batch 300 / 859]\n",
      "loss: 3.411752 [mini-batch 400 / 859]\n",
      "loss: 3.398772 [mini-batch 500 / 859]\n",
      "loss: 3.394186 [mini-batch 600 / 859]\n",
      "loss: 3.013795 [mini-batch 700 / 859]\n",
      "loss: 3.023034 [mini-batch 800 / 859]\n",
      "==> Accuracy: 16.7%, Avg loss: 3.006962\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 2.982021 [mini-batch 0 / 859]\n",
      "loss: 2.820962 [mini-batch 100 / 859]\n",
      "loss: 2.916421 [mini-batch 200 / 859]\n",
      "loss: 2.940163 [mini-batch 300 / 859]\n",
      "loss: 2.518774 [mini-batch 400 / 859]\n",
      "loss: 2.388987 [mini-batch 500 / 859]\n",
      "loss: 2.587873 [mini-batch 600 / 859]\n",
      "loss: 2.153955 [mini-batch 700 / 859]\n",
      "loss: 2.350889 [mini-batch 800 / 859]\n",
      "==> Accuracy: 24.6%, Avg loss: 2.463764\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 2.275237 [mini-batch 0 / 859]\n",
      "loss: 2.408067 [mini-batch 100 / 859]\n",
      "loss: 2.402834 [mini-batch 200 / 859]\n",
      "loss: 2.407470 [mini-batch 300 / 859]\n",
      "loss: 1.909260 [mini-batch 400 / 859]\n",
      "loss: 2.761354 [mini-batch 500 / 859]\n",
      "loss: 1.897430 [mini-batch 600 / 859]\n",
      "loss: 2.463333 [mini-batch 700 / 859]\n",
      "loss: 2.087497 [mini-batch 800 / 859]\n",
      "==> Accuracy: 30.8%, Avg loss: 2.148813\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 2.155716 [mini-batch 0 / 859]\n",
      "loss: 2.307262 [mini-batch 100 / 859]\n",
      "loss: 2.125025 [mini-batch 200 / 859]\n",
      "loss: 2.332577 [mini-batch 300 / 859]\n",
      "loss: 2.162096 [mini-batch 400 / 859]\n",
      "loss: 1.610506 [mini-batch 500 / 859]\n",
      "loss: 1.961122 [mini-batch 600 / 859]\n",
      "loss: 1.755980 [mini-batch 700 / 859]\n",
      "loss: 1.810433 [mini-batch 800 / 859]\n",
      "==> Accuracy: 36.8%, Avg loss: 1.917826\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 1.964861 [mini-batch 0 / 859]\n",
      "loss: 2.179299 [mini-batch 100 / 859]\n",
      "loss: 1.989023 [mini-batch 200 / 859]\n",
      "loss: 1.972167 [mini-batch 300 / 859]\n",
      "loss: 1.783838 [mini-batch 400 / 859]\n",
      "loss: 1.750092 [mini-batch 500 / 859]\n",
      "loss: 1.788449 [mini-batch 600 / 859]\n",
      "loss: 1.664511 [mini-batch 700 / 859]\n",
      "loss: 1.367214 [mini-batch 800 / 859]\n",
      "==> Accuracy: 41.6%, Avg loss: 1.747929\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 9.6%, Avg loss: 10.399086\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 10.986375 [mini-batch 0 / 859]\n",
      "loss: 2.832397 [mini-batch 100 / 859]\n",
      "loss: 2.308715 [mini-batch 200 / 859]\n",
      "loss: 2.102372 [mini-batch 300 / 859]\n",
      "loss: 1.438025 [mini-batch 400 / 859]\n",
      "loss: 1.457884 [mini-batch 500 / 859]\n",
      "loss: 1.055735 [mini-batch 600 / 859]\n",
      "loss: 1.225841 [mini-batch 700 / 859]\n",
      "loss: 1.441406 [mini-batch 800 / 859]\n",
      "==> Accuracy: 55.4%, Avg loss: 1.323669\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 1.327532 [mini-batch 0 / 859]\n",
      "loss: 1.386595 [mini-batch 100 / 859]\n",
      "loss: 1.408031 [mini-batch 200 / 859]\n",
      "loss: 1.071025 [mini-batch 300 / 859]\n",
      "loss: 1.087479 [mini-batch 400 / 859]\n",
      "loss: 1.103602 [mini-batch 500 / 859]\n",
      "loss: 1.124159 [mini-batch 600 / 859]\n",
      "loss: 0.915214 [mini-batch 700 / 859]\n",
      "loss: 1.086909 [mini-batch 800 / 859]\n",
      "==> Accuracy: 62.5%, Avg loss: 1.084071\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 1.205103 [mini-batch 0 / 859]\n",
      "loss: 0.927244 [mini-batch 100 / 859]\n",
      "loss: 0.975389 [mini-batch 200 / 859]\n",
      "loss: 0.713187 [mini-batch 300 / 859]\n",
      "loss: 1.092427 [mini-batch 400 / 859]\n",
      "loss: 0.865537 [mini-batch 500 / 859]\n",
      "loss: 0.953597 [mini-batch 600 / 859]\n",
      "loss: 0.944204 [mini-batch 700 / 859]\n",
      "loss: 1.072574 [mini-batch 800 / 859]\n",
      "==> Accuracy: 66.7%, Avg loss: 0.971239\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.976901 [mini-batch 0 / 859]\n",
      "loss: 0.905963 [mini-batch 100 / 859]\n",
      "loss: 0.839313 [mini-batch 200 / 859]\n",
      "loss: 0.709200 [mini-batch 300 / 859]\n",
      "loss: 0.779613 [mini-batch 400 / 859]\n",
      "loss: 0.856397 [mini-batch 500 / 859]\n",
      "loss: 0.927206 [mini-batch 600 / 859]\n",
      "loss: 1.020834 [mini-batch 700 / 859]\n",
      "loss: 1.027519 [mini-batch 800 / 859]\n",
      "==> Accuracy: 69.2%, Avg loss: 0.899150\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.755424 [mini-batch 0 / 859]\n",
      "loss: 1.063854 [mini-batch 100 / 859]\n",
      "loss: 0.919472 [mini-batch 200 / 859]\n",
      "loss: 1.095319 [mini-batch 300 / 859]\n",
      "loss: 0.754855 [mini-batch 400 / 859]\n",
      "loss: 0.884158 [mini-batch 500 / 859]\n",
      "loss: 0.802302 [mini-batch 600 / 859]\n",
      "loss: 1.021521 [mini-batch 700 / 859]\n",
      "loss: 0.687012 [mini-batch 800 / 859]\n",
      "==> Accuracy: 70.9%, Avg loss: 0.849055\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 9.1%, Avg loss: 9.728546\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 9.421099 [mini-batch 0 / 859]\n",
      "loss: 3.212691 [mini-batch 100 / 859]\n",
      "loss: 2.669459 [mini-batch 200 / 859]\n",
      "loss: 2.093804 [mini-batch 300 / 859]\n",
      "loss: 2.126558 [mini-batch 400 / 859]\n",
      "loss: 1.585121 [mini-batch 500 / 859]\n",
      "loss: 1.338387 [mini-batch 600 / 859]\n",
      "loss: 1.337602 [mini-batch 700 / 859]\n",
      "loss: 1.225628 [mini-batch 800 / 859]\n",
      "==> Accuracy: 54.5%, Avg loss: 1.313393\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 1.087075 [mini-batch 0 / 859]\n",
      "loss: 1.183321 [mini-batch 100 / 859]\n",
      "loss: 1.226070 [mini-batch 200 / 859]\n",
      "loss: 1.208237 [mini-batch 300 / 859]\n",
      "loss: 1.255248 [mini-batch 400 / 859]\n",
      "loss: 1.070220 [mini-batch 500 / 859]\n",
      "loss: 0.768476 [mini-batch 600 / 859]\n",
      "loss: 0.887007 [mini-batch 700 / 859]\n",
      "loss: 1.127026 [mini-batch 800 / 859]\n",
      "==> Accuracy: 64.1%, Avg loss: 1.041659\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.942988 [mini-batch 0 / 859]\n",
      "loss: 0.875509 [mini-batch 100 / 859]\n",
      "loss: 1.108600 [mini-batch 200 / 859]\n",
      "loss: 0.821707 [mini-batch 300 / 859]\n",
      "loss: 1.056478 [mini-batch 400 / 859]\n",
      "loss: 0.946619 [mini-batch 500 / 859]\n",
      "loss: 0.677971 [mini-batch 600 / 859]\n",
      "loss: 0.917941 [mini-batch 700 / 859]\n",
      "loss: 1.105599 [mini-batch 800 / 859]\n",
      "==> Accuracy: 68.6%, Avg loss: 0.922112\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.828050 [mini-batch 0 / 859]\n",
      "loss: 1.075050 [mini-batch 100 / 859]\n",
      "loss: 0.706854 [mini-batch 200 / 859]\n",
      "loss: 0.805282 [mini-batch 300 / 859]\n",
      "loss: 0.761528 [mini-batch 400 / 859]\n",
      "loss: 0.806963 [mini-batch 500 / 859]\n",
      "loss: 0.892998 [mini-batch 600 / 859]\n",
      "loss: 0.897375 [mini-batch 700 / 859]\n",
      "loss: 0.913544 [mini-batch 800 / 859]\n",
      "==> Accuracy: 71.1%, Avg loss: 0.853645\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.752540 [mini-batch 0 / 859]\n",
      "loss: 0.637583 [mini-batch 100 / 859]\n",
      "loss: 0.745345 [mini-batch 200 / 859]\n",
      "loss: 0.911696 [mini-batch 300 / 859]\n",
      "loss: 0.998940 [mini-batch 400 / 859]\n",
      "loss: 0.861973 [mini-batch 500 / 859]\n",
      "loss: 0.858662 [mini-batch 600 / 859]\n",
      "loss: 0.674974 [mini-batch 700 / 859]\n",
      "loss: 0.635368 [mini-batch 800 / 859]\n",
      "==> Accuracy: 72.9%, Avg loss: 0.807897\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 11.5%, Avg loss: 6.004223\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 6.305397 [mini-batch 0 / 859]\n",
      "loss: 2.478942 [mini-batch 100 / 859]\n",
      "loss: 1.972178 [mini-batch 200 / 859]\n",
      "loss: 1.977003 [mini-batch 300 / 859]\n",
      "loss: 1.703229 [mini-batch 400 / 859]\n",
      "loss: 1.553292 [mini-batch 500 / 859]\n",
      "loss: 1.288052 [mini-batch 600 / 859]\n",
      "loss: 1.321392 [mini-batch 700 / 859]\n",
      "loss: 1.193223 [mini-batch 800 / 859]\n",
      "==> Accuracy: 55.2%, Avg loss: 1.320461\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 1.225147 [mini-batch 0 / 859]\n",
      "loss: 1.430306 [mini-batch 100 / 859]\n",
      "loss: 1.062894 [mini-batch 200 / 859]\n",
      "loss: 0.951171 [mini-batch 300 / 859]\n",
      "loss: 1.129322 [mini-batch 400 / 859]\n",
      "loss: 1.214024 [mini-batch 500 / 859]\n",
      "loss: 0.794122 [mini-batch 600 / 859]\n",
      "loss: 1.536230 [mini-batch 700 / 859]\n",
      "loss: 1.024161 [mini-batch 800 / 859]\n",
      "==> Accuracy: 62.0%, Avg loss: 1.081340\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 1.015114 [mini-batch 0 / 859]\n",
      "loss: 0.782622 [mini-batch 100 / 859]\n",
      "loss: 0.906417 [mini-batch 200 / 859]\n",
      "loss: 0.918947 [mini-batch 300 / 859]\n",
      "loss: 1.016646 [mini-batch 400 / 859]\n",
      "loss: 1.116607 [mini-batch 500 / 859]\n",
      "loss: 0.928086 [mini-batch 600 / 859]\n",
      "loss: 1.399353 [mini-batch 700 / 859]\n",
      "loss: 0.896751 [mini-batch 800 / 859]\n",
      "==> Accuracy: 66.4%, Avg loss: 0.966247\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.957533 [mini-batch 0 / 859]\n",
      "loss: 0.922126 [mini-batch 100 / 859]\n",
      "loss: 0.741174 [mini-batch 200 / 859]\n",
      "loss: 0.866581 [mini-batch 300 / 859]\n",
      "loss: 0.768734 [mini-batch 400 / 859]\n",
      "loss: 0.888740 [mini-batch 500 / 859]\n",
      "loss: 0.895313 [mini-batch 600 / 859]\n",
      "loss: 0.978137 [mini-batch 700 / 859]\n",
      "loss: 1.124276 [mini-batch 800 / 859]\n",
      "==> Accuracy: 68.8%, Avg loss: 0.894688\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.766160 [mini-batch 0 / 859]\n",
      "loss: 0.909263 [mini-batch 100 / 859]\n",
      "loss: 0.971746 [mini-batch 200 / 859]\n",
      "loss: 0.945382 [mini-batch 300 / 859]\n",
      "loss: 0.813273 [mini-batch 400 / 859]\n",
      "loss: 0.784294 [mini-batch 500 / 859]\n",
      "loss: 1.251936 [mini-batch 600 / 859]\n",
      "loss: 1.043523 [mini-batch 700 / 859]\n",
      "loss: 0.712420 [mini-batch 800 / 859]\n",
      "==> Accuracy: 70.6%, Avg loss: 0.845923\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 7.3%, Avg loss: 7.784012\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 8.019411 [mini-batch 0 / 859]\n",
      "loss: 2.579116 [mini-batch 100 / 859]\n",
      "loss: 2.060987 [mini-batch 200 / 859]\n",
      "loss: 2.122764 [mini-batch 300 / 859]\n",
      "loss: 1.455068 [mini-batch 400 / 859]\n",
      "loss: 1.547599 [mini-batch 500 / 859]\n",
      "loss: 1.654104 [mini-batch 600 / 859]\n",
      "loss: 1.448957 [mini-batch 700 / 859]\n",
      "loss: 1.677487 [mini-batch 800 / 859]\n",
      "==> Accuracy: 54.8%, Avg loss: 1.323636\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 1.332517 [mini-batch 0 / 859]\n",
      "loss: 0.946272 [mini-batch 100 / 859]\n",
      "loss: 1.203237 [mini-batch 200 / 859]\n",
      "loss: 1.004148 [mini-batch 300 / 859]\n",
      "loss: 1.148836 [mini-batch 400 / 859]\n",
      "loss: 1.030576 [mini-batch 500 / 859]\n",
      "loss: 1.043755 [mini-batch 600 / 859]\n",
      "loss: 1.117785 [mini-batch 700 / 859]\n",
      "loss: 1.062778 [mini-batch 800 / 859]\n",
      "==> Accuracy: 62.5%, Avg loss: 1.069882\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 1.012657 [mini-batch 0 / 859]\n",
      "loss: 0.948563 [mini-batch 100 / 859]\n",
      "loss: 0.914055 [mini-batch 200 / 859]\n",
      "loss: 1.071669 [mini-batch 300 / 859]\n",
      "loss: 1.168845 [mini-batch 400 / 859]\n",
      "loss: 0.837750 [mini-batch 500 / 859]\n",
      "loss: 0.941041 [mini-batch 600 / 859]\n",
      "loss: 1.041166 [mini-batch 700 / 859]\n",
      "loss: 1.015421 [mini-batch 800 / 859]\n",
      "==> Accuracy: 66.1%, Avg loss: 0.957582\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.796769 [mini-batch 0 / 859]\n",
      "loss: 0.596281 [mini-batch 100 / 859]\n",
      "loss: 0.852857 [mini-batch 200 / 859]\n",
      "loss: 1.138668 [mini-batch 300 / 859]\n",
      "loss: 0.896127 [mini-batch 400 / 859]\n",
      "loss: 0.868110 [mini-batch 500 / 859]\n",
      "loss: 0.962377 [mini-batch 600 / 859]\n",
      "loss: 0.856371 [mini-batch 700 / 859]\n",
      "loss: 0.697604 [mini-batch 800 / 859]\n",
      "==> Accuracy: 68.6%, Avg loss: 0.889943\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.799996 [mini-batch 0 / 859]\n",
      "loss: 0.804177 [mini-batch 100 / 859]\n",
      "loss: 0.830554 [mini-batch 200 / 859]\n",
      "loss: 0.763777 [mini-batch 300 / 859]\n",
      "loss: 0.788598 [mini-batch 400 / 859]\n",
      "loss: 0.814729 [mini-batch 500 / 859]\n",
      "loss: 0.767743 [mini-batch 600 / 859]\n",
      "loss: 0.806197 [mini-batch 700 / 859]\n",
      "loss: 0.900924 [mini-batch 800 / 859]\n",
      "==> Accuracy: 70.4%, Avg loss: 0.843929\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 12.4%, Avg loss: 9.967014\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 8.861224 [mini-batch 0 / 859]\n",
      "loss: 2.758657 [mini-batch 100 / 859]\n",
      "loss: 2.171234 [mini-batch 200 / 859]\n",
      "loss: 1.653870 [mini-batch 300 / 859]\n",
      "loss: 1.548346 [mini-batch 400 / 859]\n",
      "loss: 1.351139 [mini-batch 500 / 859]\n",
      "loss: 1.545639 [mini-batch 600 / 859]\n",
      "loss: 1.294534 [mini-batch 700 / 859]\n",
      "loss: 1.524640 [mini-batch 800 / 859]\n",
      "==> Accuracy: 54.5%, Avg loss: 1.297743\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 1.253836 [mini-batch 0 / 859]\n",
      "loss: 1.222114 [mini-batch 100 / 859]\n",
      "loss: 1.131385 [mini-batch 200 / 859]\n",
      "loss: 1.141835 [mini-batch 300 / 859]\n",
      "loss: 0.991594 [mini-batch 400 / 859]\n",
      "loss: 1.245781 [mini-batch 500 / 859]\n",
      "loss: 0.977640 [mini-batch 600 / 859]\n",
      "loss: 1.114241 [mini-batch 700 / 859]\n",
      "loss: 1.001116 [mini-batch 800 / 859]\n",
      "==> Accuracy: 63.8%, Avg loss: 1.059950\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 1.275167 [mini-batch 0 / 859]\n",
      "loss: 1.306831 [mini-batch 100 / 859]\n",
      "loss: 1.019946 [mini-batch 200 / 859]\n",
      "loss: 1.158557 [mini-batch 300 / 859]\n",
      "loss: 1.199115 [mini-batch 400 / 859]\n",
      "loss: 1.068306 [mini-batch 500 / 859]\n",
      "loss: 1.020767 [mini-batch 600 / 859]\n",
      "loss: 0.743078 [mini-batch 700 / 859]\n",
      "loss: 1.005488 [mini-batch 800 / 859]\n",
      "==> Accuracy: 66.9%, Avg loss: 0.958322\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.870135 [mini-batch 0 / 859]\n",
      "loss: 0.840769 [mini-batch 100 / 859]\n",
      "loss: 0.989996 [mini-batch 200 / 859]\n",
      "loss: 0.909494 [mini-batch 300 / 859]\n",
      "loss: 0.978099 [mini-batch 400 / 859]\n",
      "loss: 0.922781 [mini-batch 500 / 859]\n",
      "loss: 0.904919 [mini-batch 600 / 859]\n",
      "loss: 0.823122 [mini-batch 700 / 859]\n",
      "loss: 0.727482 [mini-batch 800 / 859]\n",
      "==> Accuracy: 68.9%, Avg loss: 0.895383\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 1.342856 [mini-batch 0 / 859]\n",
      "loss: 0.750146 [mini-batch 100 / 859]\n",
      "loss: 0.740000 [mini-batch 200 / 859]\n",
      "loss: 0.840107 [mini-batch 300 / 859]\n",
      "loss: 0.848773 [mini-batch 400 / 859]\n",
      "loss: 0.977752 [mini-batch 500 / 859]\n",
      "loss: 0.882291 [mini-batch 600 / 859]\n",
      "loss: 0.698101 [mini-batch 700 / 859]\n",
      "loss: 0.920609 [mini-batch 800 / 859]\n",
      "==> Accuracy: 71.0%, Avg loss: 0.845234\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 4.9%, Avg loss: 6.769820\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 6.422719 [mini-batch 0 / 859]\n",
      "loss: 1.196479 [mini-batch 100 / 859]\n",
      "loss: 0.817294 [mini-batch 200 / 859]\n",
      "loss: 0.892513 [mini-batch 300 / 859]\n",
      "loss: 1.227892 [mini-batch 400 / 859]\n",
      "loss: 0.612316 [mini-batch 500 / 859]\n",
      "loss: 0.833950 [mini-batch 600 / 859]\n",
      "loss: 0.421866 [mini-batch 700 / 859]\n",
      "loss: 0.660392 [mini-batch 800 / 859]\n",
      "==> Accuracy: 74.9%, Avg loss: 0.732265\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.759084 [mini-batch 0 / 859]\n",
      "loss: 0.732041 [mini-batch 100 / 859]\n",
      "loss: 0.687858 [mini-batch 200 / 859]\n",
      "loss: 0.614047 [mini-batch 300 / 859]\n",
      "loss: 0.628676 [mini-batch 400 / 859]\n",
      "loss: 0.579496 [mini-batch 500 / 859]\n",
      "loss: 0.468757 [mini-batch 600 / 859]\n",
      "loss: 0.698073 [mini-batch 700 / 859]\n",
      "loss: 0.850754 [mini-batch 800 / 859]\n",
      "==> Accuracy: 79.1%, Avg loss: 0.620446\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.713540 [mini-batch 0 / 859]\n",
      "loss: 0.474196 [mini-batch 100 / 859]\n",
      "loss: 0.314862 [mini-batch 200 / 859]\n",
      "loss: 0.666785 [mini-batch 300 / 859]\n",
      "loss: 0.419214 [mini-batch 400 / 859]\n",
      "loss: 0.553181 [mini-batch 500 / 859]\n",
      "loss: 0.722048 [mini-batch 600 / 859]\n",
      "loss: 0.729468 [mini-batch 700 / 859]\n",
      "loss: 0.604489 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.9%, Avg loss: 0.569093\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.570753 [mini-batch 0 / 859]\n",
      "loss: 0.523886 [mini-batch 100 / 859]\n",
      "loss: 0.484939 [mini-batch 200 / 859]\n",
      "loss: 0.295526 [mini-batch 300 / 859]\n",
      "loss: 0.402680 [mini-batch 400 / 859]\n",
      "loss: 0.714264 [mini-batch 500 / 859]\n",
      "loss: 0.440785 [mini-batch 600 / 859]\n",
      "loss: 0.313136 [mini-batch 700 / 859]\n",
      "loss: 0.738639 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.6%, Avg loss: 0.547810\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.712616 [mini-batch 0 / 859]\n",
      "loss: 0.617647 [mini-batch 100 / 859]\n",
      "loss: 0.530240 [mini-batch 200 / 859]\n",
      "loss: 0.500271 [mini-batch 300 / 859]\n",
      "loss: 0.494041 [mini-batch 400 / 859]\n",
      "loss: 0.385481 [mini-batch 500 / 859]\n",
      "loss: 0.629051 [mini-batch 600 / 859]\n",
      "loss: 0.485449 [mini-batch 700 / 859]\n",
      "loss: 0.657815 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.9%, Avg loss: 0.523133\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 14.7%, Avg loss: 8.008342\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 8.600865 [mini-batch 0 / 859]\n",
      "loss: 1.153401 [mini-batch 100 / 859]\n",
      "loss: 1.075423 [mini-batch 200 / 859]\n",
      "loss: 1.125432 [mini-batch 300 / 859]\n",
      "loss: 0.952512 [mini-batch 400 / 859]\n",
      "loss: 0.656980 [mini-batch 500 / 859]\n",
      "loss: 0.734163 [mini-batch 600 / 859]\n",
      "loss: 0.635780 [mini-batch 700 / 859]\n",
      "loss: 0.572602 [mini-batch 800 / 859]\n",
      "==> Accuracy: 74.8%, Avg loss: 0.777208\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.778255 [mini-batch 0 / 859]\n",
      "loss: 0.679217 [mini-batch 100 / 859]\n",
      "loss: 0.700437 [mini-batch 200 / 859]\n",
      "loss: 0.907957 [mini-batch 300 / 859]\n",
      "loss: 0.612936 [mini-batch 400 / 859]\n",
      "loss: 0.626706 [mini-batch 500 / 859]\n",
      "loss: 0.884795 [mini-batch 600 / 859]\n",
      "loss: 0.522465 [mini-batch 700 / 859]\n",
      "loss: 0.500032 [mini-batch 800 / 859]\n",
      "==> Accuracy: 78.8%, Avg loss: 0.655294\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.672032 [mini-batch 0 / 859]\n",
      "loss: 0.543167 [mini-batch 100 / 859]\n",
      "loss: 0.570838 [mini-batch 200 / 859]\n",
      "loss: 0.649383 [mini-batch 300 / 859]\n",
      "loss: 0.487125 [mini-batch 400 / 859]\n",
      "loss: 0.747236 [mini-batch 500 / 859]\n",
      "loss: 0.645220 [mini-batch 600 / 859]\n",
      "loss: 0.713872 [mini-batch 700 / 859]\n",
      "loss: 0.508816 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.5%, Avg loss: 0.600305\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.711391 [mini-batch 0 / 859]\n",
      "loss: 0.585594 [mini-batch 100 / 859]\n",
      "loss: 0.763193 [mini-batch 200 / 859]\n",
      "loss: 0.633618 [mini-batch 300 / 859]\n",
      "loss: 0.526156 [mini-batch 400 / 859]\n",
      "loss: 0.468498 [mini-batch 500 / 859]\n",
      "loss: 0.485573 [mini-batch 600 / 859]\n",
      "loss: 0.534011 [mini-batch 700 / 859]\n",
      "loss: 0.533233 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.9%, Avg loss: 0.591990\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.397548 [mini-batch 0 / 859]\n",
      "loss: 0.628356 [mini-batch 100 / 859]\n",
      "loss: 0.438551 [mini-batch 200 / 859]\n",
      "loss: 0.806270 [mini-batch 300 / 859]\n",
      "loss: 0.479951 [mini-batch 400 / 859]\n",
      "loss: 0.635226 [mini-batch 500 / 859]\n",
      "loss: 0.376686 [mini-batch 600 / 859]\n",
      "loss: 0.479840 [mini-batch 700 / 859]\n",
      "loss: 0.367577 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.9%, Avg loss: 0.553378\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 10.4%, Avg loss: 8.946681\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 9.489216 [mini-batch 0 / 859]\n",
      "loss: 0.900652 [mini-batch 100 / 859]\n",
      "loss: 1.293654 [mini-batch 200 / 859]\n",
      "loss: 0.617419 [mini-batch 300 / 859]\n",
      "loss: 0.617469 [mini-batch 400 / 859]\n",
      "loss: 0.682573 [mini-batch 500 / 859]\n",
      "loss: 0.941468 [mini-batch 600 / 859]\n",
      "loss: 0.638344 [mini-batch 700 / 859]\n",
      "loss: 0.645242 [mini-batch 800 / 859]\n",
      "==> Accuracy: 75.4%, Avg loss: 0.722539\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.539997 [mini-batch 0 / 859]\n",
      "loss: 0.888857 [mini-batch 100 / 859]\n",
      "loss: 0.558796 [mini-batch 200 / 859]\n",
      "loss: 0.758491 [mini-batch 300 / 859]\n",
      "loss: 0.742992 [mini-batch 400 / 859]\n",
      "loss: 0.745164 [mini-batch 500 / 859]\n",
      "loss: 0.804533 [mini-batch 600 / 859]\n",
      "loss: 0.487310 [mini-batch 700 / 859]\n",
      "loss: 0.685932 [mini-batch 800 / 859]\n",
      "==> Accuracy: 78.4%, Avg loss: 0.630311\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.489256 [mini-batch 0 / 859]\n",
      "loss: 0.482381 [mini-batch 100 / 859]\n",
      "loss: 0.548985 [mini-batch 200 / 859]\n",
      "loss: 0.436785 [mini-batch 300 / 859]\n",
      "loss: 0.394329 [mini-batch 400 / 859]\n",
      "loss: 0.397551 [mini-batch 500 / 859]\n",
      "loss: 0.531439 [mini-batch 600 / 859]\n",
      "loss: 0.561206 [mini-batch 700 / 859]\n",
      "loss: 0.331759 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.1%, Avg loss: 0.587038\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.897079 [mini-batch 0 / 859]\n",
      "loss: 0.717134 [mini-batch 100 / 859]\n",
      "loss: 0.387698 [mini-batch 200 / 859]\n",
      "loss: 0.589403 [mini-batch 300 / 859]\n",
      "loss: 0.651934 [mini-batch 400 / 859]\n",
      "loss: 0.591634 [mini-batch 500 / 859]\n",
      "loss: 0.466881 [mini-batch 600 / 859]\n",
      "loss: 0.510412 [mini-batch 700 / 859]\n",
      "loss: 0.609975 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.2%, Avg loss: 0.558893\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.655089 [mini-batch 0 / 859]\n",
      "loss: 0.764597 [mini-batch 100 / 859]\n",
      "loss: 0.571174 [mini-batch 200 / 859]\n",
      "loss: 0.552942 [mini-batch 300 / 859]\n",
      "loss: 0.486021 [mini-batch 400 / 859]\n",
      "loss: 0.487461 [mini-batch 500 / 859]\n",
      "loss: 0.420018 [mini-batch 600 / 859]\n",
      "loss: 0.437146 [mini-batch 700 / 859]\n",
      "loss: 0.379126 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.2%, Avg loss: 0.536130\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 10.0%, Avg loss: 8.960765\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 9.157441 [mini-batch 0 / 859]\n",
      "loss: 1.490500 [mini-batch 100 / 859]\n",
      "loss: 1.233433 [mini-batch 200 / 859]\n",
      "loss: 1.076595 [mini-batch 300 / 859]\n",
      "loss: 1.068996 [mini-batch 400 / 859]\n",
      "loss: 1.060471 [mini-batch 500 / 859]\n",
      "loss: 0.733336 [mini-batch 600 / 859]\n",
      "loss: 0.538993 [mini-batch 700 / 859]\n",
      "loss: 0.608359 [mini-batch 800 / 859]\n",
      "==> Accuracy: 75.3%, Avg loss: 0.726584\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.571306 [mini-batch 0 / 859]\n",
      "loss: 0.698855 [mini-batch 100 / 859]\n",
      "loss: 0.827161 [mini-batch 200 / 859]\n",
      "loss: 0.718418 [mini-batch 300 / 859]\n",
      "loss: 0.805877 [mini-batch 400 / 859]\n",
      "loss: 0.751047 [mini-batch 500 / 859]\n",
      "loss: 1.132022 [mini-batch 600 / 859]\n",
      "loss: 0.456510 [mini-batch 700 / 859]\n",
      "loss: 0.823669 [mini-batch 800 / 859]\n",
      "==> Accuracy: 78.6%, Avg loss: 0.633837\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.549815 [mini-batch 0 / 859]\n",
      "loss: 0.613609 [mini-batch 100 / 859]\n",
      "loss: 0.604721 [mini-batch 200 / 859]\n",
      "loss: 0.714015 [mini-batch 300 / 859]\n",
      "loss: 0.671135 [mini-batch 400 / 859]\n",
      "loss: 0.476631 [mini-batch 500 / 859]\n",
      "loss: 0.612777 [mini-batch 600 / 859]\n",
      "loss: 0.554870 [mini-batch 700 / 859]\n",
      "loss: 0.467404 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.7%, Avg loss: 0.582223\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.811409 [mini-batch 0 / 859]\n",
      "loss: 0.694209 [mini-batch 100 / 859]\n",
      "loss: 0.798149 [mini-batch 200 / 859]\n",
      "loss: 0.367563 [mini-batch 300 / 859]\n",
      "loss: 0.445482 [mini-batch 400 / 859]\n",
      "loss: 0.486410 [mini-batch 500 / 859]\n",
      "loss: 0.423852 [mini-batch 600 / 859]\n",
      "loss: 0.485590 [mini-batch 700 / 859]\n",
      "loss: 0.368768 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.6%, Avg loss: 0.565282\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.478276 [mini-batch 0 / 859]\n",
      "loss: 0.514317 [mini-batch 100 / 859]\n",
      "loss: 0.455569 [mini-batch 200 / 859]\n",
      "loss: 0.361422 [mini-batch 300 / 859]\n",
      "loss: 0.542043 [mini-batch 400 / 859]\n",
      "loss: 0.296678 [mini-batch 500 / 859]\n",
      "loss: 0.224828 [mini-batch 600 / 859]\n",
      "loss: 0.637033 [mini-batch 700 / 859]\n",
      "loss: 0.323559 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.0%, Avg loss: 0.534281\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 7.6%, Avg loss: 7.935611\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 8.795699 [mini-batch 0 / 859]\n",
      "loss: 1.335876 [mini-batch 100 / 859]\n",
      "loss: 1.335783 [mini-batch 200 / 859]\n",
      "loss: 0.974812 [mini-batch 300 / 859]\n",
      "loss: 0.895342 [mini-batch 400 / 859]\n",
      "loss: 0.959646 [mini-batch 500 / 859]\n",
      "loss: 0.940131 [mini-batch 600 / 859]\n",
      "loss: 0.676196 [mini-batch 700 / 859]\n",
      "loss: 0.763187 [mini-batch 800 / 859]\n",
      "==> Accuracy: 73.3%, Avg loss: 0.767829\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.672792 [mini-batch 0 / 859]\n",
      "loss: 0.631146 [mini-batch 100 / 859]\n",
      "loss: 0.874163 [mini-batch 200 / 859]\n",
      "loss: 0.643341 [mini-batch 300 / 859]\n",
      "loss: 1.007764 [mini-batch 400 / 859]\n",
      "loss: 0.626173 [mini-batch 500 / 859]\n",
      "loss: 0.653454 [mini-batch 600 / 859]\n",
      "loss: 0.832878 [mini-batch 700 / 859]\n",
      "loss: 0.744868 [mini-batch 800 / 859]\n",
      "==> Accuracy: 78.5%, Avg loss: 0.644402\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.470853 [mini-batch 0 / 859]\n",
      "loss: 0.496626 [mini-batch 100 / 859]\n",
      "loss: 0.782907 [mini-batch 200 / 859]\n",
      "loss: 0.495252 [mini-batch 300 / 859]\n",
      "loss: 0.409151 [mini-batch 400 / 859]\n",
      "loss: 0.766504 [mini-batch 500 / 859]\n",
      "loss: 0.659917 [mini-batch 600 / 859]\n",
      "loss: 0.742910 [mini-batch 700 / 859]\n",
      "loss: 0.738621 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.0%, Avg loss: 0.591211\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.558306 [mini-batch 0 / 859]\n",
      "loss: 0.630420 [mini-batch 100 / 859]\n",
      "loss: 0.681460 [mini-batch 200 / 859]\n",
      "loss: 0.481583 [mini-batch 300 / 859]\n",
      "loss: 0.584978 [mini-batch 400 / 859]\n",
      "loss: 0.712149 [mini-batch 500 / 859]\n",
      "loss: 0.655743 [mini-batch 600 / 859]\n",
      "loss: 0.482605 [mini-batch 700 / 859]\n",
      "loss: 0.489094 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.0%, Avg loss: 0.569360\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.842480 [mini-batch 0 / 859]\n",
      "loss: 0.571143 [mini-batch 100 / 859]\n",
      "loss: 0.766331 [mini-batch 200 / 859]\n",
      "loss: 0.494989 [mini-batch 300 / 859]\n",
      "loss: 0.367874 [mini-batch 400 / 859]\n",
      "loss: 0.490834 [mini-batch 500 / 859]\n",
      "loss: 0.630305 [mini-batch 600 / 859]\n",
      "loss: 0.958384 [mini-batch 700 / 859]\n",
      "loss: 0.553718 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.1%, Avg loss: 0.546488\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 8.1%, Avg loss: 6.092537\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 6.217917 [mini-batch 0 / 859]\n",
      "loss: 0.740911 [mini-batch 100 / 859]\n",
      "loss: 0.677184 [mini-batch 200 / 859]\n",
      "loss: 0.600321 [mini-batch 300 / 859]\n",
      "loss: 0.590561 [mini-batch 400 / 859]\n",
      "loss: 0.570718 [mini-batch 500 / 859]\n",
      "loss: 0.608785 [mini-batch 600 / 859]\n",
      "loss: 0.525825 [mini-batch 700 / 859]\n",
      "loss: 0.544646 [mini-batch 800 / 859]\n",
      "==> Accuracy: 80.8%, Avg loss: 0.535669\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.577543 [mini-batch 0 / 859]\n",
      "loss: 0.359837 [mini-batch 100 / 859]\n",
      "loss: 0.503296 [mini-batch 200 / 859]\n",
      "loss: 0.546972 [mini-batch 300 / 859]\n",
      "loss: 0.698631 [mini-batch 400 / 859]\n",
      "loss: 0.535158 [mini-batch 500 / 859]\n",
      "loss: 0.474369 [mini-batch 600 / 859]\n",
      "loss: 0.415616 [mini-batch 700 / 859]\n",
      "loss: 0.571337 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.4%, Avg loss: 0.471869\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.421786 [mini-batch 0 / 859]\n",
      "loss: 0.382856 [mini-batch 100 / 859]\n",
      "loss: 0.457468 [mini-batch 200 / 859]\n",
      "loss: 0.505471 [mini-batch 300 / 859]\n",
      "loss: 0.524299 [mini-batch 400 / 859]\n",
      "loss: 0.462995 [mini-batch 500 / 859]\n",
      "loss: 0.410156 [mini-batch 600 / 859]\n",
      "loss: 0.460380 [mini-batch 700 / 859]\n",
      "loss: 0.378901 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.0%, Avg loss: 0.455483\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.563234 [mini-batch 0 / 859]\n",
      "loss: 0.581816 [mini-batch 100 / 859]\n",
      "loss: 0.511139 [mini-batch 200 / 859]\n",
      "loss: 0.344213 [mini-batch 300 / 859]\n",
      "loss: 0.400823 [mini-batch 400 / 859]\n",
      "loss: 0.740415 [mini-batch 500 / 859]\n",
      "loss: 0.370280 [mini-batch 600 / 859]\n",
      "loss: 0.445666 [mini-batch 700 / 859]\n",
      "loss: 0.602064 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.8%, Avg loss: 0.447047\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.265692 [mini-batch 0 / 859]\n",
      "loss: 0.332462 [mini-batch 100 / 859]\n",
      "loss: 0.493005 [mini-batch 200 / 859]\n",
      "loss: 0.408748 [mini-batch 300 / 859]\n",
      "loss: 0.391259 [mini-batch 400 / 859]\n",
      "loss: 0.454499 [mini-batch 500 / 859]\n",
      "loss: 0.424772 [mini-batch 600 / 859]\n",
      "loss: 0.298687 [mini-batch 700 / 859]\n",
      "loss: 0.274601 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.9%, Avg loss: 0.424375\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 13.2%, Avg loss: 5.698095\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 5.428395 [mini-batch 0 / 859]\n",
      "loss: 0.729325 [mini-batch 100 / 859]\n",
      "loss: 0.828071 [mini-batch 200 / 859]\n",
      "loss: 0.663376 [mini-batch 300 / 859]\n",
      "loss: 0.545972 [mini-batch 400 / 859]\n",
      "loss: 0.418888 [mini-batch 500 / 859]\n",
      "loss: 0.672739 [mini-batch 600 / 859]\n",
      "loss: 0.444183 [mini-batch 700 / 859]\n",
      "loss: 0.480281 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.4%, Avg loss: 0.528484\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.406750 [mini-batch 0 / 859]\n",
      "loss: 0.578049 [mini-batch 100 / 859]\n",
      "loss: 0.494127 [mini-batch 200 / 859]\n",
      "loss: 0.498033 [mini-batch 300 / 859]\n",
      "loss: 0.529198 [mini-batch 400 / 859]\n",
      "loss: 0.358518 [mini-batch 500 / 859]\n",
      "loss: 0.474553 [mini-batch 600 / 859]\n",
      "loss: 0.445212 [mini-batch 700 / 859]\n",
      "loss: 0.561264 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.7%, Avg loss: 0.482493\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.498432 [mini-batch 0 / 859]\n",
      "loss: 0.231096 [mini-batch 100 / 859]\n",
      "loss: 0.334060 [mini-batch 200 / 859]\n",
      "loss: 0.336124 [mini-batch 300 / 859]\n",
      "loss: 0.420171 [mini-batch 400 / 859]\n",
      "loss: 0.447512 [mini-batch 500 / 859]\n",
      "loss: 0.494763 [mini-batch 600 / 859]\n",
      "loss: 0.314185 [mini-batch 700 / 859]\n",
      "loss: 0.639482 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.7%, Avg loss: 0.438929\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.318124 [mini-batch 0 / 859]\n",
      "loss: 0.426757 [mini-batch 100 / 859]\n",
      "loss: 0.332227 [mini-batch 200 / 859]\n",
      "loss: 0.394617 [mini-batch 300 / 859]\n",
      "loss: 0.395300 [mini-batch 400 / 859]\n",
      "loss: 0.542429 [mini-batch 500 / 859]\n",
      "loss: 0.501391 [mini-batch 600 / 859]\n",
      "loss: 0.365756 [mini-batch 700 / 859]\n",
      "loss: 0.512787 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.9%, Avg loss: 0.440027\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.397814 [mini-batch 0 / 859]\n",
      "loss: 0.524344 [mini-batch 100 / 859]\n",
      "loss: 0.344475 [mini-batch 200 / 859]\n",
      "loss: 0.393302 [mini-batch 300 / 859]\n",
      "loss: 0.739412 [mini-batch 400 / 859]\n",
      "loss: 0.367407 [mini-batch 500 / 859]\n",
      "loss: 0.197205 [mini-batch 600 / 859]\n",
      "loss: 0.501389 [mini-batch 700 / 859]\n",
      "loss: 0.237384 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.7%, Avg loss: 0.434699\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 4.4%, Avg loss: 4.862796\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 5.086568 [mini-batch 0 / 859]\n",
      "loss: 0.712143 [mini-batch 100 / 859]\n",
      "loss: 0.444940 [mini-batch 200 / 859]\n",
      "loss: 0.719348 [mini-batch 300 / 859]\n",
      "loss: 0.529805 [mini-batch 400 / 859]\n",
      "loss: 0.647687 [mini-batch 500 / 859]\n",
      "loss: 0.673558 [mini-batch 600 / 859]\n",
      "loss: 0.761454 [mini-batch 700 / 859]\n",
      "loss: 0.261739 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.2%, Avg loss: 0.533066\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.571548 [mini-batch 0 / 859]\n",
      "loss: 0.325707 [mini-batch 100 / 859]\n",
      "loss: 0.423629 [mini-batch 200 / 859]\n",
      "loss: 0.402297 [mini-batch 300 / 859]\n",
      "loss: 0.483351 [mini-batch 400 / 859]\n",
      "loss: 0.513828 [mini-batch 500 / 859]\n",
      "loss: 0.558669 [mini-batch 600 / 859]\n",
      "loss: 0.447130 [mini-batch 700 / 859]\n",
      "loss: 0.330948 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.4%, Avg loss: 0.504898\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.547698 [mini-batch 0 / 859]\n",
      "loss: 0.381421 [mini-batch 100 / 859]\n",
      "loss: 0.412540 [mini-batch 200 / 859]\n",
      "loss: 0.870941 [mini-batch 300 / 859]\n",
      "loss: 0.455206 [mini-batch 400 / 859]\n",
      "loss: 0.360021 [mini-batch 500 / 859]\n",
      "loss: 0.482156 [mini-batch 600 / 859]\n",
      "loss: 0.555828 [mini-batch 700 / 859]\n",
      "loss: 0.427433 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.0%, Avg loss: 0.459440\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.505049 [mini-batch 0 / 859]\n",
      "loss: 0.387135 [mini-batch 100 / 859]\n",
      "loss: 0.322016 [mini-batch 200 / 859]\n",
      "loss: 0.378045 [mini-batch 300 / 859]\n",
      "loss: 0.579382 [mini-batch 400 / 859]\n",
      "loss: 0.430214 [mini-batch 500 / 859]\n",
      "loss: 0.592294 [mini-batch 600 / 859]\n",
      "loss: 0.503573 [mini-batch 700 / 859]\n",
      "loss: 0.435657 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.1%, Avg loss: 0.501488\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.428128 [mini-batch 0 / 859]\n",
      "loss: 0.423276 [mini-batch 100 / 859]\n",
      "loss: 0.447920 [mini-batch 200 / 859]\n",
      "loss: 0.483814 [mini-batch 300 / 859]\n",
      "loss: 0.430323 [mini-batch 400 / 859]\n",
      "loss: 0.306850 [mini-batch 500 / 859]\n",
      "loss: 0.321453 [mini-batch 600 / 859]\n",
      "loss: 0.488076 [mini-batch 700 / 859]\n",
      "loss: 0.337952 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.7%, Avg loss: 0.438809\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 8.7%, Avg loss: 6.381625\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 6.540195 [mini-batch 0 / 859]\n",
      "loss: 0.683100 [mini-batch 100 / 859]\n",
      "loss: 0.653741 [mini-batch 200 / 859]\n",
      "loss: 0.717737 [mini-batch 300 / 859]\n",
      "loss: 0.429142 [mini-batch 400 / 859]\n",
      "loss: 0.509677 [mini-batch 500 / 859]\n",
      "loss: 0.516606 [mini-batch 600 / 859]\n",
      "loss: 0.506856 [mini-batch 700 / 859]\n",
      "loss: 0.720796 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.4%, Avg loss: 0.539874\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.315699 [mini-batch 0 / 859]\n",
      "loss: 0.649457 [mini-batch 100 / 859]\n",
      "loss: 0.485958 [mini-batch 200 / 859]\n",
      "loss: 0.501579 [mini-batch 300 / 859]\n",
      "loss: 0.319445 [mini-batch 400 / 859]\n",
      "loss: 0.465759 [mini-batch 500 / 859]\n",
      "loss: 0.330921 [mini-batch 600 / 859]\n",
      "loss: 0.482745 [mini-batch 700 / 859]\n",
      "loss: 0.653067 [mini-batch 800 / 859]\n",
      "==> Accuracy: 81.3%, Avg loss: 0.534753\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.508516 [mini-batch 0 / 859]\n",
      "loss: 0.480459 [mini-batch 100 / 859]\n",
      "loss: 0.601358 [mini-batch 200 / 859]\n",
      "loss: 0.470144 [mini-batch 300 / 859]\n",
      "loss: 0.275812 [mini-batch 400 / 859]\n",
      "loss: 0.667712 [mini-batch 500 / 859]\n",
      "loss: 0.400601 [mini-batch 600 / 859]\n",
      "loss: 0.450888 [mini-batch 700 / 859]\n",
      "loss: 0.543821 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.7%, Avg loss: 0.460215\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.590428 [mini-batch 0 / 859]\n",
      "loss: 0.544183 [mini-batch 100 / 859]\n",
      "loss: 0.422570 [mini-batch 200 / 859]\n",
      "loss: 0.410248 [mini-batch 300 / 859]\n",
      "loss: 0.325648 [mini-batch 400 / 859]\n",
      "loss: 0.380854 [mini-batch 500 / 859]\n",
      "loss: 0.368386 [mini-batch 600 / 859]\n",
      "loss: 0.520971 [mini-batch 700 / 859]\n",
      "loss: 0.596246 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.5%, Avg loss: 0.447523\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.515284 [mini-batch 0 / 859]\n",
      "loss: 0.209120 [mini-batch 100 / 859]\n",
      "loss: 0.402217 [mini-batch 200 / 859]\n",
      "loss: 0.321887 [mini-batch 300 / 859]\n",
      "loss: 0.407567 [mini-batch 400 / 859]\n",
      "loss: 0.286529 [mini-batch 500 / 859]\n",
      "loss: 0.360543 [mini-batch 600 / 859]\n",
      "loss: 0.472138 [mini-batch 700 / 859]\n",
      "loss: 0.515310 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.7%, Avg loss: 0.437401\n",
      "\n",
      "Pre-train stats\n",
      "==> Accuracy: 8.2%, Avg loss: 8.379592\n",
      "\n",
      "Epoch 0\n",
      "--------------------\n",
      "loss: 8.175385 [mini-batch 0 / 859]\n",
      "loss: 0.824139 [mini-batch 100 / 859]\n",
      "loss: 0.600207 [mini-batch 200 / 859]\n",
      "loss: 0.493018 [mini-batch 300 / 859]\n",
      "loss: 0.459462 [mini-batch 400 / 859]\n",
      "loss: 0.449031 [mini-batch 500 / 859]\n",
      "loss: 0.685759 [mini-batch 600 / 859]\n",
      "loss: 0.744929 [mini-batch 700 / 859]\n",
      "loss: 0.571883 [mini-batch 800 / 859]\n",
      "==> Accuracy: 79.7%, Avg loss: 0.571127\n",
      "\n",
      "Epoch 1\n",
      "--------------------\n",
      "loss: 0.260143 [mini-batch 0 / 859]\n",
      "loss: 0.482058 [mini-batch 100 / 859]\n",
      "loss: 0.719754 [mini-batch 200 / 859]\n",
      "loss: 0.513080 [mini-batch 300 / 859]\n",
      "loss: 0.884059 [mini-batch 400 / 859]\n",
      "loss: 0.602029 [mini-batch 500 / 859]\n",
      "loss: 0.594603 [mini-batch 600 / 859]\n",
      "loss: 0.315374 [mini-batch 700 / 859]\n",
      "loss: 0.697404 [mini-batch 800 / 859]\n",
      "==> Accuracy: 82.2%, Avg loss: 0.510263\n",
      "\n",
      "Epoch 2\n",
      "--------------------\n",
      "loss: 0.693113 [mini-batch 0 / 859]\n",
      "loss: 0.311628 [mini-batch 100 / 859]\n",
      "loss: 0.406698 [mini-batch 200 / 859]\n",
      "loss: 0.607316 [mini-batch 300 / 859]\n",
      "loss: 0.291564 [mini-batch 400 / 859]\n",
      "loss: 0.433231 [mini-batch 500 / 859]\n",
      "loss: 0.449407 [mini-batch 600 / 859]\n",
      "loss: 0.484795 [mini-batch 700 / 859]\n",
      "loss: 0.449423 [mini-batch 800 / 859]\n",
      "==> Accuracy: 83.8%, Avg loss: 0.473357\n",
      "\n",
      "Epoch 3\n",
      "--------------------\n",
      "loss: 0.406500 [mini-batch 0 / 859]\n",
      "loss: 0.430778 [mini-batch 100 / 859]\n",
      "loss: 0.729267 [mini-batch 200 / 859]\n",
      "loss: 0.412784 [mini-batch 300 / 859]\n",
      "loss: 0.299978 [mini-batch 400 / 859]\n",
      "loss: 0.463938 [mini-batch 500 / 859]\n",
      "loss: 0.459009 [mini-batch 600 / 859]\n",
      "loss: 0.386892 [mini-batch 700 / 859]\n",
      "loss: 0.281383 [mini-batch 800 / 859]\n",
      "==> Accuracy: 84.8%, Avg loss: 0.446978\n",
      "\n",
      "Epoch 4\n",
      "--------------------\n",
      "loss: 0.389277 [mini-batch 0 / 859]\n",
      "loss: 0.305929 [mini-batch 100 / 859]\n",
      "loss: 0.409090 [mini-batch 200 / 859]\n",
      "loss: 0.561811 [mini-batch 300 / 859]\n",
      "loss: 0.184587 [mini-batch 400 / 859]\n",
      "loss: 0.464634 [mini-batch 500 / 859]\n",
      "loss: 0.371817 [mini-batch 600 / 859]\n",
      "loss: 0.289229 [mini-batch 700 / 859]\n",
      "loss: 0.271659 [mini-batch 800 / 859]\n",
      "==> Accuracy: 85.2%, Avg loss: 0.431452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etas = [1e-6, 1e-5, 1e-4, 1e-3]\n",
    "n_trials = 5\n",
    "\n",
    "results = {eta:[] for eta in etas}\n",
    "for eta in etas:\n",
    "    for _ in range(n_trials):\n",
    "        nn = NeuralNetwork(\n",
    "            [28*28, 512, 128, 64, 10], # layers size\n",
    "            eta,                      # learning rate\n",
    "            64,                        # mini batch size\n",
    "            5 # training epochs\n",
    "        )\n",
    "        accuracy, _ = nn.train(train_data, validation_data)\n",
    "        results[eta].append( accuracy[-1] )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad289417-4080-4b27-b67d-305482d0fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for eta, values in results.items():\n",
    "    for value in values:\n",
    "        x.append( eta )\n",
    "        y.append( 100 * value )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "841f048b-574d-44e9-8a5d-fe51aa5fff97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy sensitivity to Learning rate parameter')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, y, \"b+\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Accuracy % (Validation dataset)\")\n",
    "plt.title(\"Accuracy sensitivity to Learning rate parameter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
